{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8659cdef",
   "metadata": {},
   "source": [
    "# 원핫인코딩 (One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476235a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 얘기한 장단점에 맞게 정수 인코딩이랑 원핫인코딩에 맞게 사용하세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e827d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"The Little Prince, written by Antoine de Saint-Exupéry, is a poetic tale about a young prince who travels from his home planet to Earth. The story begins with a pilot stranded in the Sahara Desert after his plane crashes. While trying to fix his plane, he meets a mysterious young boy, the Little Prince.\n",
    "\n",
    "The Little Prince comes from a small asteroid called B-612, where he lives alone with a rose that he loves deeply. He recounts his journey to the pilot, describing his visits to several other planets. Each planet is inhabited by a different character, such as a king, a vain man, a drunkard, a businessman, a geographer, and a fox. Through these encounters, the Prince learns valuable lessons about love, responsibility, and the nature of adult behavior.\n",
    "\n",
    "On Earth, the Little Prince meets various creatures, including a fox, who teaches him about relationships and the importance of taming, which means building ties with others. The fox's famous line, \"You become responsible, forever, for what you have tamed,\" resonates with the Prince's feelings for his rose.\n",
    "\n",
    "Ultimately, the Little Prince realizes that the essence of life is often invisible and can only be seen with the heart. After sharing his wisdom with the pilot, he prepares to return to his asteroid and his beloved rose. The story concludes with the pilot reflecting on the lessons learned from the Little Prince and the enduring impact of their friendship.\n",
    "\n",
    "The narrative is a beautifully simple yet profound exploration of love, loss, and the importance of seeing beyond the surface of things.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd52f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 문장 토큰화 \n",
    "sentences = sent_tokenize(raw_text)\n",
    "\n",
    "# 영어 불용어 리스트 \n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')  \n",
    "\n",
    "# 단어사전 (key=단어, value=빈도)\n",
    "vocab = {}\n",
    "\n",
    "\n",
    "# 토큰화/정제/정규화 처리 결과 \n",
    "preprocessed_sentences = []\n",
    "\n",
    "# 토큰 만큼 반복\n",
    "for sentence in sentences : \n",
    "    sentence = sentence.lower() # 대소문자 정규화 (소문자 변환)\n",
    "\n",
    "    tokens = word_tokenize(sentence) # 단어 토큰화\n",
    "    tokens = [token for token in tokens if token not in en_stopwords] # 불용어 제거 \n",
    "    tokens = [token for token in tokens if len(token) > 2]  # 단어 길이가 2 이하면 제거 \n",
    "\n",
    "    for token in tokens :\n",
    "        if token not in vocab:\n",
    "            vocab[token] = 1\n",
    "        else :\n",
    "            vocab[token] += 1\n",
    "    \n",
    "    preprocessed_sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 15, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "\n",
    "padded_seqs = pad_sequences(sequences, maxlen=10, truncating='pre')  # 정수 인코딩을 진행한 다음에 원핫인코딩 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed96178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 10, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_encodded = to_categorical(padded_seqs)\n",
    "one_hot_encodded.shape # (13, 10, 15) : 문장 갯수 13, 토큰 개수 10, 차원 개수 15(num_words 개수 + 1 개의 차원으로 반환함.- to_categorical 작동 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d67e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  7,  2,  1,  1,  8,  9],\n",
       "       [ 0,  0, 10,  1,  4,  1,  1,  1, 11,  1],\n",
       "       [ 0,  1,  1, 11, 12,  1,  7,  1,  3,  2],\n",
       "       [ 1,  1, 13,  1,  1,  1,  1,  5,  1,  1],\n",
       "       [ 0,  0,  0,  1,  1,  4,  1,  1,  1,  1],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  6],\n",
       "       [ 1,  2,  1,  1, 14,  1,  1,  1,  1,  1],\n",
       "       [ 1,  6,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  2,  1,  5],\n",
       "       [ 1,  3,  2,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 0,  0,  1,  1,  4,  1,  1, 13,  1,  5],\n",
       "       [ 1,  4,  1, 14,  1,  3,  2,  1,  1,  1],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs  # 문장 갯수 13, 토큰 개수 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a25529",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed63c8",
   "metadata": {},
   "source": [
    "### 한국어 전처리 \n",
    "1. 토큰화 (형태소 분석)\n",
    "2. 시퀀스 처리 Tokenizer\n",
    "3. 패딩 처리 pad_sequences\n",
    "4. one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86684276",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"나는 오늘 학원에 간다\", \n",
    "    \"친구들이랑 맛있는 점심 먹을 생각에 신난다.\", \n",
    "    \"오늘은 강사님이 무슨 간식을 줄까?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6bb2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "ko_stopwords = ['은', '는', '이', '가', '을', '를', '와', '과', '에', '의', '으로', '나', '내', '우리', '들']\n",
    "\n",
    "preprocessed_texts = []\n",
    "\n",
    "for text in texts :\n",
    "    tokens = okt.morphs(text, stem=True)  # stem : 기본 형태로 반환하게 해주는 \n",
    "    tokens = [token for token in tokens if token not in ko_stopwords]  # 불용어 처리 \n",
    "    tokens = [token for token in tokens if not re.search(r'[\\s.,:;?!]', token)] # 공백문자(\\), 구두점 제거 \n",
    "    preprocessed_texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31b11c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['오늘', '학원', '간다'],\n",
       " ['친구', '이랑', '맛있다', '점심', '먹다', '생각', '신나다'],\n",
       " ['오늘', '강사', '님', '무슨', '간식', '주다']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7999da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4], [5, 6, 7, 8, 9, 10, 11], [2, 12, 13, 14, 15, 16]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시퀀스 처리 \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(preprocessed_texts)\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_texts)  \n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ea873c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '오늘': 2,\n",
       " '학원': 3,\n",
       " '간다': 4,\n",
       " '친구': 5,\n",
       " '이랑': 6,\n",
       " '맛있다': 7,\n",
       " '점심': 8,\n",
       " '먹다': 9,\n",
       " '생각': 10,\n",
       " '신나다': 11,\n",
       " '강사': 12,\n",
       " '님': 13,\n",
       " '무슨': 14,\n",
       " '간식': 15,\n",
       " '주다': 16}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f5587c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4],\n",
       "       [ 9, 10, 11],\n",
       "       [14, 15, 16]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패딩 처리 \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_seqs = pad_sequences(sequences, maxlen=3)\n",
    "padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫 인코딩 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_encodded = to_categorical(padded_seqs)\n",
    "# one_hot_encodded\n",
    "one_hot_encodded.shape # 문장 3개, 3개 자리로 자르기(maxlen=3), 차원 16?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5c378",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m17\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">217</span> (868.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m217\u001b[0m (868.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">217</span> (868.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m217\u001b[0m (868.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 간단한 모델 구조 확인해보기 \n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "input = layers.Input(shape=(3, 17))   # 입력층 정의 - 원핫 인코딩을 한 친구를 넣을거기 때문에 3개의 단어를 17개 차원으로 가지고 있기 떄문에 동일하게 만들었음\n",
    "x = layers.SimpleRNN(8)(input)        # rnn 모델에 입력 (목요일 설명) - 8개의 노드를 만듦 > 출력층 정의 \n",
    "output = layers.Dense(1, activation='sigmoid')(x)  # 2진분류를 하기 위해 시그모이드를 활성합수로 정의 \n",
    "\n",
    "model = models.Model(inputs=input, outputs=output)\n",
    "model.summary()                                     # 각 레이어에 대한 설명 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dda8abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step - accuracy: 0.3333 - loss: 0.9253\n",
      "Epoch 2/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3333 - loss: 0.9156\n",
      "Epoch 3/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3333 - loss: 0.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x223e350c6e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # 모델에 대한 추가 설정 추가 / 최적화 함수를 adam / 성능평가를 accuracy 사용 \n",
    "labels = np.array([1, 0, 1])  # 임의의 값으로 라벨 지정 \n",
    "\n",
    "model.fit(one_hot_encodded, labels, epochs=3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed523a6",
   "metadata": {},
   "source": [
    "반드시 알아야할것 \n",
    "- 품사 태깅(형태소 이해하기 위해 설명) > 형태소 처리 / 토큰화 처리를 통해 정제와 정규화 진행 (둘의 차이점: 정제는 노이즈 제거, 정규화는 표기 통일(도메인 지식에 맞게 진행))\n",
    "- 형태를 안맞추면 노이즈 발생 > 어간이나 표제어 추출 (형태 맞추기)\n",
    "- 정규 표현식 \n",
    "- 텍스트 데이터 전처리가 완료됐을 때 컴퓨터가 이해하기 쉽게 인코딩 진행\n",
    "    - 입력 데이터의 길이를 맞추기 위해 진행하는 것이 패딩\n",
    "    - 어쩌구가 어쩌구 \n",
    "    - 정수 인코딩 \n",
    "    - 원핫인코딩\n",
    "        - 순서에 영향을 덜 받음. \n",
    "- 모델에 적용하는 순서를 확인하기 위해 keras를 이용한 모델돌리는 것 진행 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
