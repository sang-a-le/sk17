{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39c2beb",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "- hyper parameter : 모델 설정과 관련해 직접 지정할 수 있는 매개변수 \n",
    "- model parameter : 회귀계수(가중치), 절편 등 모델의 학습 대상이 되는 변수 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afcab7",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a85a02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'n_naighbors' for estimator KNeighborsClassifier(). Valid parameters are: ['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 첫 번째 인자: 모델\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 두 번째 인자: 테스트 할 파라미터 (딕셔너리)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# scoring: 평가 지표 (accuracy, precision, recall, f1)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# cv: 반복 횟수\u001b[39;00m\n\u001b[32m     16\u001b[39m grid = GridSearchCV(knn, params, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, cv=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43miris_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miris_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m최적의 파라미터:\u001b[39m\u001b[33m'\u001b[39m, grid.best_params_)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m최적화된 모델 객체:\u001b[39m\u001b[33m'\u001b[39m, grid.best_estimator_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:854\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    847\u001b[39m score_params_test = _check_method_params(X, params=score_params, indices=test)\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[32m    851\u001b[39m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[32m    852\u001b[39m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[32m    853\u001b[39m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     estimator = \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m start_time = time.time()\n\u001b[32m    858\u001b[39m X_train, y_train = _safe_split(estimator, X, y, train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:283\u001b[39m, in \u001b[36mBaseEstimator.set_params\u001b[39m\u001b[34m(self, **params)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[32m    282\u001b[39m     local_valid_params = \u001b[38;5;28mself\u001b[39m._get_param_names()\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    284\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     )\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[32m    289\u001b[39m     nested_params[key][sub_key] = value\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter 'n_naighbors' for estimator KNeighborsClassifier(). Valid parameters are: ['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_naighbors' : range(1, 13, 2)\n",
    "}\n",
    "\n",
    "# 첫 번째 인자: 모델\n",
    "# 두 번째 인자: 테스트 할 파라미터 (딕셔너리)\n",
    "# scoring: 평가 지표 (accuracy, precision, recall, f1)\n",
    "# cv: 반복 횟수\n",
    "grid = GridSearchCV(knn, params, scoring='accuracy', cv=5)\n",
    "grid.fit(iris_input, iris_target)\n",
    "\n",
    "print('최적의 파라미터:', grid.best_params_)\n",
    "print('최적화된 모델 객체:', grid.best_estimator_)\n",
    "print('최적화된 점수: ', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a6a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_knn = \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[32m      2\u001b[39m best_knn.score(iris_input, iris_target)\n",
      "\u001b[31mAttributeError\u001b[39m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "best_knn.score(iris_input, iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27288cac",
   "metadata": {},
   "source": [
    "### RandomSearchCV \n",
    "- 하이퍼 파라미터의 값 목록이나 값의 범위를 제공하는데, 이 범위 중에 랜덤하게 값을 뽑아내 최적의 하이퍼 파라미터 조합을 찾는다. \n",
    "    - 탐색 범위가 넓을 때 짧은 시간 내에 좋은 결과를 얻을 수 있다. \n",
    "    - 랜덤하게 값을 추출해 계산하므로, 전역 최적값을 놓칠 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터:  {'n_neighbors': 31}\n",
      "최적화된 모델 객체:  KNeighborsClassifier(n_neighbors=31)\n",
      "최적화된 점수:  0.9333333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 546, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.93333333\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_neighbors' : range(1, 1000, 2)\n",
    "}\n",
    "\n",
    "rd_search = RandomizedSearchCV(knn, params, cv=5, n_iter=10, random_state=0)\n",
    "rd_search.fit(iris_input, iris_target)\n",
    "\n",
    "print('최적의 파라미터: ', rd_search.best_params_)\n",
    "print('최적화된 모델 객체: ', rd_search.best_estimator_)\n",
    "print('최적화된 점수: ', rd_search.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa5740",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c188cf4",
   "metadata": {},
   "source": [
    "깃 설명 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adaf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: six in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (1.17.0)\n",
      "Collecting networkx>=2.2 (from hyperopt)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting tqdm (from hyperopt)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting cloudpickle (from hyperopt)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 728.2 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.8/1.6 MB 798.0 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 867.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 894.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 894.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 918.8 kB/s eta 0:00:00\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: py4j, tqdm, networkx, future, cloudpickle, hyperopt\n",
      "\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   ---------------------------------------- 6/6 [hyperopt]\n",
      "\n",
      "Successfully installed cloudpickle-3.1.1 future-1.0.0 hyperopt-0.2.7 networkx-3.5 py4j-0.10.9.9 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c895cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp \n",
    "\n",
    "# 검색 공간 : 하이퍼파라미터 최적화 시 사용하는 범위 지정(검색 공간)\n",
    "search_space = {\n",
    "    'x' : hp.quniform('x', -10, 10, 1),\n",
    "    'y' : hp.quniform('y', -15, 15, 1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50bc2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt \n",
    "\n",
    "# 목적 함수 \n",
    "def objective(search_space) :\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    return { \n",
    "        'loss' : x ** 2 + 20 * y, \n",
    "        'status' : hyperopt.STATUS_OK    # STATUS_OK 현재의 계산이 잘 끝났는지 물어보는 것 \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc2565cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 85.77trial/s, best loss: -300.0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': np.float64(-0.0), 'y': np.float64(-15.0)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials   # 목적함수에 대한 loss 를 최고화 하는 함수\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_val = fmin(            # 함수 호출 구문\n",
    "    fn = objective,         # 목적함수\n",
    "    space = search_space,   \n",
    "    algo = tpe.suggest,     # 베이지안 함수 기반 탐색 방법\n",
    "    max_evals = 500,        # 반복횟수\n",
    "    trials = trials         # 목적함수의 값을 최소화 시키는 값을 찾아가면서 해당 결과 저장\n",
    ")\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9b951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 189.0, 'status': 'ok'},\n",
       " {'loss': 289.0, 'status': 'ok'},\n",
       " {'loss': 109.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': 201.0, 'status': 'ok'},\n",
       " {'loss': -115.0, 'status': 'ok'},\n",
       " {'loss': -119.0, 'status': 'ok'},\n",
       " {'loss': -84.0, 'status': 'ok'},\n",
       " {'loss': 121.0, 'status': 'ok'},\n",
       " {'loss': 289.0, 'status': 'ok'},\n",
       " {'loss': 56.0, 'status': 'ok'},\n",
       " {'loss': 264.0, 'status': 'ok'},\n",
       " {'loss': 64.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': 76.0, 'status': 'ok'},\n",
       " {'loss': 81.0, 'status': 'ok'},\n",
       " {'loss': -20.0, 'status': 'ok'},\n",
       " {'loss': -56.0, 'status': 'ok'},\n",
       " {'loss': 196.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': -151.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': 184.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -40.0, 'status': 'ok'},\n",
       " {'loss': -95.0, 'status': 'ok'},\n",
       " {'loss': -140.0, 'status': 'ok'},\n",
       " {'loss': 64.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -76.0, 'status': 'ok'},\n",
       " {'loss': 149.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': 89.0, 'status': 'ok'},\n",
       " {'loss': -36.0, 'status': 'ok'},\n",
       " {'loss': 221.0, 'status': 'ok'},\n",
       " {'loss': 380.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': 45.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': 204.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -131.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': 20.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': 320.0, 'status': 'ok'},\n",
       " {'loss': 69.0, 'status': 'ok'},\n",
       " {'loss': -135.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -111.0, 'status': 'ok'},\n",
       " {'loss': 104.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -175.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -59.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': 16.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -84.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': 176.0, 'status': 'ok'},\n",
       " {'loss': -44.0, 'status': 'ok'},\n",
       " {'loss': -111.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': 76.0, 'status': 'ok'},\n",
       " {'loss': 301.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -20.0, 'status': 'ok'},\n",
       " {'loss': 264.0, 'status': 'ok'},\n",
       " {'loss': -59.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': 204.0, 'status': 'ok'},\n",
       " {'loss': -95.0, 'status': 'ok'},\n",
       " {'loss': 24.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': -91.0, 'status': 'ok'},\n",
       " {'loss': 101.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -71.0, 'status': 'ok'},\n",
       " {'loss': 156.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -96.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 180.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': 4.0, 'status': 'ok'},\n",
       " {'loss': -104.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': 156.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': 40.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': -19.0, 'status': 'ok'},\n",
       " {'loss': 241.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': 160.0, 'status': 'ok'},\n",
       " {'loss': -35.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': -115.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -119.0, 'status': 'ok'},\n",
       " {'loss': 309.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -36.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': 249.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 96.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -76.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': -160.0, 'status': 'ok'},\n",
       " {'loss': 284.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': 1.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -120.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 121.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': 89.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': 44.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -59.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': 36.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': 161.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -100.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': 229.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -11.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -96.0, 'status': 'ok'},\n",
       " {'loss': 261.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -140.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': 229.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 136.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -151.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': 64.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': 249.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': 21.0, 'status': 'ok'},\n",
       " {'loss': 289.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': 141.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': 209.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': 40.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': 4.0, 'status': 'ok'},\n",
       " {'loss': -80.0, 'status': 'ok'},\n",
       " {'loss': -75.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -151.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': -160.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': 129.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -104.0, 'status': 'ok'},\n",
       " {'loss': 101.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -19.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': 181.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': 96.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': 40.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -215.0, 'status': 'ok'},\n",
       " {'loss': -44.0, 'status': 'ok'},\n",
       " {'loss': 224.0, 'status': 'ok'},\n",
       " {'loss': 149.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -131.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': 161.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -111.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': 20.0, 'status': 'ok'},\n",
       " {'loss': 325.0, 'status': 'ok'},\n",
       " {'loss': 261.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -95.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -20.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': 200.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': 289.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': 1.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -100.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': 120.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -160.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -36.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': 244.0, 'status': 'ok'},\n",
       " {'loss': 81.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -255.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results   # loss, status 로 구성된 딕셔너리 - 목적함수에서 봄?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32d0f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [np.float64(3.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0)],\n",
       " 'y': [np.float64(9.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.vals   # 하이퍼파라미터 값. 적용했던 값들을 리스트로 가지고 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1498371",
   "metadata": {},
   "source": [
    "- hyperopt를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f7be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:13<00:00,  3.76trial/s, best loss: -0.9671361502347416]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': np.float64(0.6403349404192222),\n",
       " 'learning_rate': np.float64(0.1351017557199938),\n",
       " 'max_depth': np.float64(4.0),\n",
       " 'n_estimators': np.float64(400.0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "import hyperopt\n",
    "\n",
    "# 0. 데이터 로드 및 분리 (유방암 데이터 로드)\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=0)\n",
    "\n",
    "\n",
    "# 1. 검색 공간\n",
    "# n_estimators, max_depth, learning_rate, colsample_bytree\n",
    "search_space = {\n",
    "    \"n_estimators\": hp.quniform('n_estimators', 100, 500, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2), \n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "# 2. 목적 함수 \n",
    "# cross_val_score - accuracy(평가지표) : 이진분류임. / accuracy의 경우, 값이 클 수록 성능이 좋다는 뜻 -> (-) 음수로 변환해줘야 성능지표로 쓸 수 있음. \n",
    "def xgb_objective(ss) :\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators = int(ss['n_estimators']), \n",
    "        max_depth = int(ss['max_depth']), \n",
    "        learning_rate = ss['learning_rate'], \n",
    "        colsample_bytree = ss['colsample_bytree']\n",
    "    )\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    return { \n",
    "        'loss' : -1 * mean_acc,\n",
    "        'status' : hyperopt.STATUS_OK   \n",
    "    }\n",
    "\n",
    "\n",
    "# 3. Trials() + fmin()\n",
    "# 50 반복\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(     \n",
    "    fn = xgb_objective,\n",
    "    space = search_space,   \n",
    "    algo = tpe.suggest,     # 베이지안 함수 기반 탐색 방법\n",
    "    max_evals = 50,        # 반복횟수\n",
    "    trials = trials         # 목적함수의 값을 최소화 시키는 값을 찾아가면서 해당 결과 저장\n",
    ") \n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418d70a",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70c123",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.42-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "Downloading sqlalchemy-2.0.42-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 817.9 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 931.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   ---------------------------------------- 6/6 [optuna]\n",
      "\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.4 colorlog-6.9.0 greenlet-3.2.4 optuna-4.4.0 sqlalchemy-2.0.42\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e31a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:21:07,951] A new study created in memory with name: no-name-4a02262a-239a-48d5-b611-65c34247a8ef\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\2501295960.py:5: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\2501295960.py:6: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-08-11 10:21:07,953] Trial 0 finished with value: 208.09434365760814 and parameters: {'x': -7.004717928901338, 'y': 5.392303056624563}. Best is trial 0 with value: 208.09434365760814.\n",
      "[I 2025-08-11 10:21:07,954] Trial 1 finished with value: 10.675579272058835 and parameters: {'x': 6.033542752230346, 'y': -3.786246465525405}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,956] Trial 2 finished with value: 377.87165820473416 and parameters: {'x': -5.966121597576571, 'y': 12.247617855872303}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,958] Trial 3 finished with value: 135.5760108598713 and parameters: {'x': -4.675849894974265, 'y': 3.755417708464563}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,958] Trial 4 finished with value: 240.08969997581355 and parameters: {'x': 5.077225526560191, 'y': 10.354961220648534}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,960] Trial 5 finished with value: 130.9176055242644 and parameters: {'x': -4.401508060099541, 'y': 3.7255535045374586}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,961] Trial 6 finished with value: 520.7021358507079 and parameters: {'x': -9.146329699597729, 'y': 14.317577764289656}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,962] Trial 7 finished with value: 62.719756868126616 and parameters: {'x': -2.2676785492918006, 'y': -10.913655347537397}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,963] Trial 8 finished with value: 95.20525134960555 and parameters: {'x': 1.6051079794055028, 'y': 4.657097265767149}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,964] Trial 9 finished with value: 145.2484800538277 and parameters: {'x': -4.747624308867538, 'y': -14.231619447446505}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,975] Trial 10 finished with value: 41.792539332894826 and parameters: {'x': 9.454995842162948, 'y': -5.3543557683372525}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,984] Trial 11 finished with value: 46.15158266380369 and parameters: {'x': 9.788302681441976, 'y': -5.265573660085789}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:07,994] Trial 12 finished with value: 49.088201493593104 and parameters: {'x': 9.987534019416845, 'y': -4.487584327830061}. Best is trial 1 with value: 10.675579272058835.\n",
      "[I 2025-08-11 10:21:08,002] Trial 13 finished with value: 7.753896446353136 and parameters: {'x': 5.706445156530586, 'y': -4.34498010637442}. Best is trial 13 with value: 7.753896446353136.\n",
      "[I 2025-08-11 10:21:08,011] Trial 14 finished with value: 16.975273402982403 and parameters: {'x': 4.803792353092917, 'y': -1.2957313070045906}. Best is trial 13 with value: 7.753896446353136.\n",
      "[I 2025-08-11 10:21:08,019] Trial 15 finished with value: 23.41469773317407 and parameters: {'x': 5.379592707053265, 'y': -9.213340276041443}. Best is trial 13 with value: 7.753896446353136.\n",
      "[I 2025-08-11 10:21:08,026] Trial 16 finished with value: 24.01221298224064 and parameters: {'x': 1.7149394198190429, 'y': -0.2712758287773198}. Best is trial 13 with value: 7.753896446353136.\n",
      "[I 2025-08-11 10:21:08,035] Trial 17 finished with value: 23.615381044093056 and parameters: {'x': 6.734383702592948, 'y': -8.109623675929491}. Best is trial 13 with value: 7.753896446353136.\n",
      "[I 2025-08-11 10:21:08,040] Trial 18 finished with value: 5.219549435695668 and parameters: {'x': 2.317179492285558, 'y': -2.8197923057790435}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,040] Trial 19 finished with value: 96.47053591997887 and parameters: {'x': -0.06279165233021367, 'y': -14.332193912172809}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,054] Trial 20 finished with value: 34.350155951990274 and parameters: {'x': 2.042917268282931, 'y': 0.7822269582436201}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,057] Trial 21 finished with value: 23.923703783174304 and parameters: {'x': 7.372594880386334, 'y': -2.808170217559418}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,057] Trial 22 finished with value: 8.87587196148534 and parameters: {'x': 3.9609690417820387, 'y': -7.820001855003264}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,070] Trial 23 finished with value: 6.410644490985147 and parameters: {'x': 3.3136475959237117, 'y': -7.512423068783684}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,073] Trial 24 finished with value: 41.34022580105952 and parameters: {'x': 3.2581308595419163, 'y': -11.424452837433837}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,073] Trial 25 finished with value: 51.74729282334618 and parameters: {'x': -0.3392739394833928, 'y': 1.3715416015618418}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,088] Trial 26 finished with value: 28.333235244828337 and parameters: {'x': -1.932460622514811, 'y': -7.001016604671021}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,088] Trial 27 finished with value: 25.34782503760715 and parameters: {'x': 7.119608703630261, 'y': -2.1057558557404055}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,098] Trial 28 finished with value: 42.32079329407819 and parameters: {'x': 3.27306845021296, 'y': -11.499709756256543}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,108] Trial 29 finished with value: 65.20146775798867 and parameters: {'x': 8.235820164692143, 'y': 1.1471664172195473}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,133] Trial 30 finished with value: 6.904306388323533 and parameters: {'x': 0.873349153730286, 'y': -6.54326360884453}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,142] Trial 31 finished with value: 5.405272299308319 and parameters: {'x': 1.0548262765490621, 'y': -6.2734093940694535}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,163] Trial 32 finished with value: 23.51579701083545 and parameters: {'x': -1.429504957856178, 'y': -6.973647090835387}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,174] Trial 33 finished with value: 157.50020321021947 and parameters: {'x': 1.1486047835153659, 'y': 7.4125959799953725}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,180] Trial 34 finished with value: 26.74434836503989 and parameters: {'x': 2.8407605968264624, 'y': -10.16904161112259}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,186] Trial 35 finished with value: 7.281438066861374 and parameters: {'x': 0.5400023296616041, 'y': -6.10898581090609}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,194] Trial 36 finished with value: 39.769162791825295 and parameters: {'x': -2.9026934590143263, 'y': -2.7802313812618253}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,201] Trial 37 finished with value: 29.27018000762431 and parameters: {'x': -0.7403943944830003, 'y': -8.908916701765907}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,208] Trial 38 finished with value: 61.32407785445696 and parameters: {'x': 4.5525168084774315, 'y': -12.675530562368442}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,216] Trial 39 finished with value: 8.190505765027464 and parameters: {'x': 0.6667442390644485, 'y': -3.3427663655692585}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,223] Trial 40 finished with value: 98.80911333084919 and parameters: {'x': -3.260039725280989, 'y': 2.7214646258823922}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,228] Trial 41 finished with value: 6.363323154995639 and parameters: {'x': 0.6318241072635435, 'y': -5.868945393023939}. Best is trial 18 with value: 5.219549435695668.\n",
      "[I 2025-08-11 10:21:08,239] Trial 42 finished with value: 1.9372619836762968 and parameters: {'x': 2.435397750770183, 'y': -6.272197423295979}. Best is trial 42 with value: 1.9372619836762968.\n",
      "[I 2025-08-11 10:21:08,246] Trial 43 finished with value: 14.097147903833726 and parameters: {'x': 2.6103899066171197, 'y': -1.2656524158873603}. Best is trial 42 with value: 1.9372619836762968.\n",
      "[I 2025-08-11 10:21:08,252] Trial 44 finished with value: 0.6770310225888577 and parameters: {'x': 2.1875615575510277, 'y': -5.130287373985147}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,259] Trial 45 finished with value: 17.00052652174787 and parameters: {'x': -1.1200722336843696, 'y': -4.840214797396767}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,264] Trial 46 finished with value: 2.409350924283244 and parameters: {'x': 2.3526972950014278, 'y': -3.5892023063582874}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,272] Trial 47 finished with value: 16.930112824932422 and parameters: {'x': 4.103558107502478, 'y': -1.0361291231552494}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,272] Trial 48 finished with value: 2.3059738171594306 and parameters: {'x': 2.0131034191512507, 'y': -3.8458730763609754}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,272] Trial 49 finished with value: 119.4011275845031 and parameters: {'x': -7.867744487197664, 'y': -3.8627852685231843}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,287] Trial 50 finished with value: 8.944307506753205 and parameters: {'x': 2.1170338816575165, 'y': -2.1426098725213576}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,288] Trial 51 finished with value: 2.2351779405796535 and parameters: {'x': 1.5928438928824362, 'y': -4.494936013181105}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,288] Trial 52 finished with value: 1.1182039051981936 and parameters: {'x': 2.1330419145144086, 'y': -4.394535233717641}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,304] Trial 53 finished with value: 0.9863956376393622 and parameters: {'x': 3.9079761607723547, 'y': -4.597538909820518}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,304] Trial 54 finished with value: 8.504768537107257 and parameters: {'x': 5.910554501489695, 'y': -4.817131109902946}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,304] Trial 55 finished with value: 16.932095169715023 and parameters: {'x': 3.9441739525544377, 'y': -9.00507561939007}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,320] Trial 56 finished with value: 4.194182038155686 and parameters: {'x': 5.046272945512356, 'y': -5.083361085764725}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,320] Trial 57 finished with value: 21.710308696337307 and parameters: {'x': 1.7546385444689396, 'y': -0.5100797845156686}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,320] Trial 58 finished with value: 9.071240931395389 and parameters: {'x': 0.07879474429312294, 'y': -4.26665097980163}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,336] Trial 59 finished with value: 355.6369652808205 and parameters: {'x': 3.531041470737889, 'y': 13.850860994585291}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,336] Trial 60 finished with value: 12.552640516724324 and parameters: {'x': 1.5747570046148174, 'y': -8.24365887861683}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,336] Trial 61 finished with value: 1.9371730635543696 and parameters: {'x': 2.790968775831901, 'y': -3.623962569231071}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,358] Trial 62 finished with value: 2.9908757911843806 and parameters: {'x': 4.6787828575690735, 'y': -5.415408122593428}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,358] Trial 63 finished with value: 9.530162430270792 and parameters: {'x': 2.657018518146235, 'y': -1.9320159496216105}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,370] Trial 64 finished with value: 28.64644007391385 and parameters: {'x': 2.987573703442072, 'y': 0.3522224973432957}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,373] Trial 65 finished with value: 4.317841292164291 and parameters: {'x': 1.4446485277743326, 'y': -3.6220583865744747}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,373] Trial 66 finished with value: 49.75623591766018 and parameters: {'x': 4.050779093841005, 'y': 1.9751056775942004}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,388] Trial 67 finished with value: 14.070806206667365 and parameters: {'x': 0.043544625304525075, 'y': -7.308717787886082}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,388] Trial 68 finished with value: 10.003939290962705 and parameters: {'x': 5.364531372742109, 'y': -2.8993023353464156}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,396] Trial 69 finished with value: 33.41480625451293 and parameters: {'x': 6.431894691138325, 'y': -9.651548675812123}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,404] Trial 70 finished with value: 0.7821874630497485 and parameters: {'x': 3.495166980810005, 'y': -5.7328008762039335}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,410] Trial 71 finished with value: 1.1106992966864264 and parameters: {'x': 3.523214814617837, 'y': -5.914847284769895}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,415] Trial 72 finished with value: 1.3066408888660528 and parameters: {'x': 3.667964619639297, 'y': -5.927612071814604}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,422] Trial 73 finished with value: 1.9282021905451345 and parameters: {'x': 3.538169113708285, 'y': -6.280068824554201}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,423] Trial 74 finished with value: 11.814410121582469 and parameters: {'x': 3.605899294811854, 'y': -8.38338531150813}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,423] Trial 75 finished with value: 2.2188764676404524 and parameters: {'x': 4.339024969563841, 'y': -5.652601408614023}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,438] Trial 76 finished with value: 10.32934838147224 and parameters: {'x': 5.514129242295712, 'y': -7.002124505245822}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,438] Trial 77 finished with value: 130.28338377158678 and parameters: {'x': 3.2062998877445192, 'y': 6.412310201177646}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,453] Trial 78 finished with value: 32.74237631003048 and parameters: {'x': 7.868829352684752, 'y': -8.00613989103399}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,460] Trial 79 finished with value: 10.218254168501405 and parameters: {'x': 4.746511604739493, 'y': -2.3226969945462494}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,460] Trial 80 finished with value: 1.767004031291252 and parameters: {'x': 3.5724221194027974, 'y': -6.199723696735903}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,472] Trial 81 finished with value: 2.2327151249821533 and parameters: {'x': 3.496081156032552, 'y': -6.409474587075468}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,474] Trial 82 finished with value: 11.40212889920064 and parameters: {'x': 6.334338617085735, 'y': -5.5332118582809535}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,474] Trial 83 finished with value: 23.414667760193787 and parameters: {'x': 2.8461148402913468, 'y': -9.836422967216084}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,488] Trial 84 finished with value: 32.84756701169124 and parameters: {'x': 3.8733776536695546, 'y': -10.664342723190565}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,488] Trial 85 finished with value: 7.8974216579033 and parameters: {'x': 4.373192035410493, 'y': -7.451890146761981}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,488] Trial 86 finished with value: 6.998866522582264 and parameters: {'x': 5.164219612643993, 'y': -6.521518974850247}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,507] Trial 87 finished with value: 0.9537006416778282 and parameters: {'x': 2.2299574275465943, 'y': -4.399387747138664}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,507] Trial 88 finished with value: 4.437296840876181 and parameters: {'x': 1.0378859550482826, 'y': -4.233576282021889}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,507] Trial 89 finished with value: 198.1645117261492 and parameters: {'x': 2.1462851477388747, 'y': 9.051180828570173}. Best is trial 44 with value: 0.6770310225888577.\n",
      "[I 2025-08-11 10:21:08,527] Trial 90 finished with value: 0.03277009101774215 and parameters: {'x': 3.1773603826749985, 'y': -4.963759336717987}. Best is trial 90 with value: 0.03277009101774215.\n",
      "[I 2025-08-11 10:21:08,529] Trial 91 finished with value: 0.41131398419434667 and parameters: {'x': 3.641337336011099, 'y': -4.999363107125644}. Best is trial 90 with value: 0.03277009101774215.\n",
      "[I 2025-08-11 10:21:08,529] Trial 92 finished with value: 0.23427840304653805 and parameters: {'x': 3.2635567292970427, 'y': -4.594024319091915}. Best is trial 90 with value: 0.03277009101774215.\n",
      "[I 2025-08-11 10:21:08,547] Trial 93 finished with value: 0.02161324615668983 and parameters: {'x': 3.051204988571694, 'y': -4.862191091354505}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,547] Trial 94 finished with value: 0.3503584543690087 and parameters: {'x': 2.4173240746802893, 'y': -4.895850009976824}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,547] Trial 95 finished with value: 4.282190009660603 and parameters: {'x': 3.0979774028959897, 'y': -2.932975462607577}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,560] Trial 96 finished with value: 0.32094561030299923 and parameters: {'x': 2.440859631045903, 'y': -4.908853644566139}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,560] Trial 97 finished with value: 2.661333561474395 and parameters: {'x': 1.369924536567265, 'y': -5.064711243141739}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,576] Trial 98 finished with value: 177.34843924135185 and parameters: {'x': -9.904719130047152, 'y': -1.7111303741335444}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,576] Trial 99 finished with value: 0.32612296547061087 and parameters: {'x': 2.441257390851405, 'y': -4.881976010097815}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,590] Trial 100 finished with value: 3.809902379063222 and parameters: {'x': 2.4006185411029115, 'y': -3.142409020856954}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,600] Trial 101 finished with value: 6.474981322619662 and parameters: {'x': 0.4554174668452786, 'y': -4.990996968090514}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,608] Trial 102 finished with value: 2.145571057437735 and parameters: {'x': 1.7555564173008422, 'y': -4.227386754632941}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,621] Trial 103 finished with value: 19.138594887602476 and parameters: {'x': 2.606419513228607, 'y': -0.6429724251463282}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,630] Trial 104 finished with value: 5.872519704553597 and parameters: {'x': 4.382523342744857, 'y': -6.9902635281085725}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,630] Trial 105 finished with value: 6.144711451030268 and parameters: {'x': 3.0397316780337382, 'y': -2.521465585312382}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,637] Trial 106 finished with value: 1.0588109700176491 and parameters: {'x': 2.008653713932233, 'y': -5.275759879455468}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,647] Trial 107 finished with value: 3.9014715528744577 and parameters: {'x': 4.887381598560488, 'y': -4.417537765782437}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,654] Trial 108 finished with value: 2.5922233556575787 and parameters: {'x': 4.056220459838348, 'y': -3.784836761633875}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,654] Trial 109 finished with value: 11.58864863603901 and parameters: {'x': -0.3971199828332703, 'y': -4.780399320871056}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,654] Trial 110 finished with value: 12.328698098250296 and parameters: {'x': 2.7119470863440838, 'y': -1.5006109651562554}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,669] Trial 111 finished with value: 1.11420877792711 and parameters: {'x': 2.011784724020647, 'y': -5.370997771217242}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,669] Trial 112 finished with value: 6.779739812606392 and parameters: {'x': 1.130625318047836, 'y': -3.1874939693665465}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,669] Trial 113 finished with value: 0.26409098954028815 and parameters: {'x': 3.127079158417901, 'y': -5.497937623639835}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,689] Trial 114 finished with value: 7.328692487358934 and parameters: {'x': 3.096828510821343, 'y': -7.705423576235532}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,689] Trial 115 finished with value: 2.996653655844339 and parameters: {'x': 4.183045922995632, 'y': -3.73625318994359}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,689] Trial 116 finished with value: 77.0317114097123 and parameters: {'x': -5.630805357746233, 'y': -6.59402330171526}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,704] Trial 117 finished with value: 0.3291320601221626 and parameters: {'x': 2.6085465658010536, 'y': -4.580600108516927}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,704] Trial 118 finished with value: 16.375279302024595 and parameters: {'x': 1.7727994596541115, 'y': -8.856067703736457}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,719] Trial 119 finished with value: 0.9492832658016664 and parameters: {'x': 2.7166417024496683, 'y': -5.932197050526896}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,720] Trial 120 finished with value: 0.8793416265834868 and parameters: {'x': 2.456644944987394, 'y': -5.764268873352654}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,720] Trial 121 finished with value: 0.536225689800907 and parameters: {'x': 2.438729643286224, 'y': -5.4703203976815145}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,735] Trial 122 finished with value: 3.7647958115497513 and parameters: {'x': 3.2059266288745505, 'y': -6.929349640441077}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,735] Trial 123 finished with value: 0.5156011752786605 and parameters: {'x': 2.47283902975446, 'y': -5.487547419979268}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,735] Trial 124 finished with value: 2.1765381238892787 and parameters: {'x': 1.5278796004801831, 'y': -5.096951808682941}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,751] Trial 125 finished with value: 7.288929169549953 and parameters: {'x': 0.3625391396976475, 'y': -5.576826993060422}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,751] Trial 126 finished with value: 5.961025369537106 and parameters: {'x': 0.850847814605558, 'y': -3.841479282208816}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,767] Trial 127 finished with value: 6.238766390576162 and parameters: {'x': 3.2486044188409227, 'y': -7.485349519385338}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,767] Trial 128 finished with value: 3.478932144799133 and parameters: {'x': 3.7901858787337064, 'y': -6.689537931462024}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,767] Trial 129 finished with value: 0.36727970395553783 and parameters: {'x': 2.417627792694783, 'y': -4.832302903680513}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,788] Trial 130 finished with value: 3.3643877118577747 and parameters: {'x': 2.4147536471332987, 'y': -3.2616460606901714}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,788] Trial 131 finished with value: 0.030560058466445512 and parameters: {'x': 2.825422790230859, 'y': -5.009102543362538}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,799] Trial 132 finished with value: 0.19473872082275206 and parameters: {'x': 2.8149009238258857, 'y': -4.599404127801794}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,804] Trial 133 finished with value: 0.2685768828610897 and parameters: {'x': 2.6969377732118196, 'y': -4.579607124756759}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,804] Trial 134 finished with value: 5.746064873109109 and parameters: {'x': 2.9757191958627347, 'y': -2.6030278859236686}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,804] Trial 135 finished with value: 1.4191165007234359 and parameters: {'x': 1.8461804730129245, 'y': -4.703660667702113}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,820] Trial 136 finished with value: 2.9756273148097643 and parameters: {'x': 1.3546196968692803, 'y': -4.481973965056557}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,820] Trial 137 finished with value: 1.3678797415137227 and parameters: {'x': 2.8373709662118425, 'y': -3.841798144154978}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,836] Trial 138 finished with value: 1.012377477820858 and parameters: {'x': 3.3591788588848495, 'y': -4.0601233989767405}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,836] Trial 139 finished with value: 10.465143667286142 and parameters: {'x': 4.5240848679279, 'y': -2.1465268561559343}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,836] Trial 140 finished with value: 2.3258146155390214 and parameters: {'x': 3.9660113790624236, 'y': -6.180100263139084}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,851] Trial 141 finished with value: 0.4614231973073656 and parameters: {'x': 2.381601522143885, 'y': -5.281080984580255}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,863] Trial 142 finished with value: 0.13830664672954707 and parameters: {'x': 2.6555922781814023, 'y': -4.859679054018046}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,867] Trial 143 finished with value: 0.030855117977220205 and parameters: {'x': 2.843831905463919, 'y': -4.919584552316175}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,872] Trial 144 finished with value: 2.5139534258288765 and parameters: {'x': 2.8756608508262222, 'y': -3.4193377331600474}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,872] Trial 145 finished with value: 0.4998920412602532 and parameters: {'x': 3.684817829644964, 'y': -4.824168883696275}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,888] Trial 146 finished with value: 1.0527527761352606 and parameters: {'x': 2.038304397117077, 'y': -4.642376813488118}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,888] Trial 147 finished with value: 3.13258476683286 and parameters: {'x': 3.0626337131667816, 'y': -3.2311976411119865}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,901] Trial 148 finished with value: 0.6946714084005761 and parameters: {'x': 3.353189620810793, 'y': -4.245063909888986}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,904] Trial 149 finished with value: 4.909032849683399 and parameters: {'x': 1.318395526138586, 'y': -6.442650076481708}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,904] Trial 150 finished with value: 82.8894438959642 and parameters: {'x': 1.7031791216024559, 'y': 4.011531473912546}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,920] Trial 151 finished with value: 0.21215236144583832 and parameters: {'x': 2.6182291457744045, 'y': -5.257688525762591}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,920] Trial 152 finished with value: 0.10606264482683012 and parameters: {'x': 2.77542879027574, 'y': -4.764138988830683}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,920] Trial 153 finished with value: 0.8070358438296554 and parameters: {'x': 2.719449188419116, 'y': -4.146579185893054}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,941] Trial 154 finished with value: 1.7342104501479507 and parameters: {'x': 2.056703221420343, 'y': -5.918913291703408}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,947] Trial 155 finished with value: 0.14595738461448576 and parameters: {'x': 2.8765048044803625, 'y': -4.63846670789808}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,954] Trial 156 finished with value: 4.487848236328723 and parameters: {'x': 3.196599399293885, 'y': -2.8906880476027244}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,954] Trial 157 finished with value: 65.13072591471291 and parameters: {'x': 2.738314262566811, 'y': -13.066117187937264}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,954] Trial 158 finished with value: 3.0572969977541224 and parameters: {'x': 4.172437655860524, 'y': -3.702815764482777}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,971] Trial 159 finished with value: 5.294316970733727 and parameters: {'x': 2.0851660215305268, 'y': -7.111254547081295}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,982] Trial 160 finished with value: 1.1080666879963854 and parameters: {'x': 3.6880860741844486, 'y': -5.796620513487959}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,988] Trial 161 finished with value: 0.2853232611274318 and parameters: {'x': 2.4850431963381885, 'y': -4.858074838418826}. Best is trial 93 with value: 0.02161324615668983.\n",
      "[I 2025-08-11 10:21:08,988] Trial 162 finished with value: 0.012144058631626434 and parameters: {'x': 2.9395451424031416, 'y': -5.092137228222744}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:08,988] Trial 163 finished with value: 0.35365286297621334 and parameters: {'x': 2.911392609818566, 'y': -4.411951028075511}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,009] Trial 164 finished with value: 0.16586964059103404 and parameters: {'x': 3.3752195557801765, 'y': -5.1583664281063415}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,009] Trial 165 finished with value: 1.8528491290116944 and parameters: {'x': 3.3555169993365115, 'y': -6.313947027925577}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,020] Trial 166 finished with value: 0.8398639987274523 and parameters: {'x': 3.8743760748794283, 'y': -5.274463983804609}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,020] Trial 167 finished with value: 1.615859355660634 and parameters: {'x': 3.2403296018065517, 'y': -3.7517608249393315}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,020] Trial 168 finished with value: 2.9287980838955656 and parameters: {'x': 4.646546824812536, 'y': -5.466563647957404}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,040] Trial 169 finished with value: 0.7479158374168446 and parameters: {'x': 2.8195807376163886, 'y': -5.845792366469335}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,046] Trial 170 finished with value: 4.758401789984541 and parameters: {'x': 1.7083191024274824, 'y': -6.757828845146989}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,053] Trial 171 finished with value: 0.5158305367114702 and parameters: {'x': 2.5538755575623595, 'y': -4.437146983155305}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,062] Trial 172 finished with value: 0.6202142115440061 and parameters: {'x': 2.2127684151810953, 'y': -4.978076418916566}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,068] Trial 173 finished with value: 1.0298437090889236 and parameters: {'x': 3.313015079104697, 'y': -4.034668311230796}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,080] Trial 174 finished with value: 0.11482054218094725 and parameters: {'x': 2.7598721471905625, 'y': -5.239079811958426}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,090] Trial 175 finished with value: 0.09415398511453095 and parameters: {'x': 2.927761731737058, 'y': -5.298220753323611}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,098] Trial 176 finished with value: 1.198290968191392 and parameters: {'x': 3.6753724789978257, 'y': -5.861488817573231}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,098] Trial 177 finished with value: 1.9594178039710881 and parameters: {'x': 3.1818930315415987, 'y': -6.387923891662542}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,109] Trial 178 finished with value: 41.73730764822663 and parameters: {'x': 9.246653735845761, 'y': -3.35178133954538}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,109] Trial 179 finished with value: 1.1134948809180372 and parameters: {'x': 4.043333755835331, 'y': -5.157954280893489}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,125] Trial 180 finished with value: 0.07506258595750251 and parameters: {'x': 2.8143021439810383, 'y': -5.201442031928452}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,125] Trial 181 finished with value: 0.030822845364913913 and parameters: {'x': 2.911226997610026, 'y': -5.151466826109163}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,125] Trial 182 finished with value: 0.2263431646045676 and parameters: {'x': 2.898873004462773, 'y': -5.464883313723112}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,140] Trial 183 finished with value: 0.390571041109617 and parameters: {'x': 3.035365095022922, 'y': -5.62395540799294}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,140] Trial 184 finished with value: 1.8755080450275678 and parameters: {'x': 3.589842848852764, 'y': -6.235958518189354}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,140] Trial 185 finished with value: 4.866201827911841 and parameters: {'x': 2.943931382298356, 'y': -7.20523425921621}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,161] Trial 186 finished with value: 2.1402108477250508 and parameters: {'x': 4.190126013068031, 'y': -4.149229219622675}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,163] Trial 187 finished with value: 0.6334156648977944 and parameters: {'x': 3.501868350826306, 'y': -5.617692337119927}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,172] Trial 188 finished with value: 1.0960270823935865 and parameters: {'x': 2.016828801319125, 'y': -5.359724167214267}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,172] Trial 189 finished with value: 0.4890806465115392 and parameters: {'x': 2.9349464413660766, 'y': -4.303689235311846}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,192] Trial 190 finished with value: 1.3988198884563492 and parameters: {'x': 2.779027870060604, 'y': -6.161891219627034}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,198] Trial 191 finished with value: 0.24523536052139827 and parameters: {'x': 2.5307278271759857, 'y': -4.8418260820033}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,205] Trial 192 finished with value: 0.08609222558212345 and parameters: {'x': 3.293293245345895, 'y': -5.008443803443717}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,205] Trial 193 finished with value: 0.18529737779493594 and parameters: {'x': 3.314279971043343, 'y': -5.29415213342067}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,205] Trial 194 finished with value: 0.7634365718286534 and parameters: {'x': 3.868868714063588, 'y': -4.907784331319776}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,221] Trial 195 finished with value: 2.4117822665356696 and parameters: {'x': 3.4226700793285434, 'y': -3.505633153949114}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,221] Trial 196 finished with value: 3.735104271253333 and parameters: {'x': 2.079179223430605, 'y': -6.699174319689263}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,236] Trial 197 finished with value: 0.28844154662401933 and parameters: {'x': 3.4020557283910002, 'y': -5.35607967913376}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,236] Trial 198 finished with value: 0.9437814107120359 and parameters: {'x': 3.0101175863075844, 'y': -4.028568558693232}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,255] Trial 199 finished with value: 0.8494633790768895 and parameters: {'x': 3.8510299900299807, 'y': -4.646147862594472}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,258] Trial 200 finished with value: 2.6990471979458817 and parameters: {'x': 4.417608329421611, 'y': -5.8303215174258405}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,271] Trial 201 finished with value: 0.014626104379835502 and parameters: {'x': 3.071923761551457, 'y': -5.097226935075239}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,273] Trial 202 finished with value: 0.16815071302502446 and parameters: {'x': 2.627876237034971, 'y': -5.172263223184089}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,283] Trial 203 finished with value: 0.2444838218457237 and parameters: {'x': 3.1840422387538108, 'y': -5.45892513136699}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,289] Trial 204 finished with value: 1.1898049092822711 and parameters: {'x': 2.7937892395893753, 'y': -6.071112520500598}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,289] Trial 205 finished with value: 1.3693959441555137 and parameters: {'x': 2.264326666498857, 'y': -4.0899556656234655}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,303] Trial 206 finished with value: 0.30731265499514787 and parameters: {'x': 3.550598497908063, 'y': -5.064451137278813}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,307] Trial 207 finished with value: 0.2203671680040794 and parameters: {'x': 3.0715127056698113, 'y': -4.53604622974712}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,307] Trial 208 finished with value: 2.9366303024211615 and parameters: {'x': 2.86844879121378, 'y': -6.708603108357247}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,323] Trial 209 finished with value: 1.2869150730615289 and parameters: {'x': 1.9030022005483034, 'y': -5.288982527256691}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,323] Trial 210 finished with value: 109.87947671822783 and parameters: {'x': -7.386807814008261, 'y': -3.5880155266134226}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,323] Trial 211 finished with value: 0.28470122276943455 and parameters: {'x': 3.213283157116079, 'y': -4.510907454912639}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,343] Trial 212 finished with value: 0.352754593014865 and parameters: {'x': 2.6214561768233278, 'y': -4.542332908163965}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,343] Trial 213 finished with value: 0.4041440469736131 and parameters: {'x': 3.624906059358316, 'y': -5.116775271144512}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,355] Trial 214 finished with value: 1.4457262405257527 and parameters: {'x': 2.3903196129801785, 'y': -6.036347464033716}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,355] Trial 215 finished with value: 0.9543866255243024 and parameters: {'x': 3.0313480515967224, 'y': -4.0235759501193185}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,355] Trial 216 finished with value: 4.373913958137341 and parameters: {'x': 3.4352373169463024, 'y': -2.954399248124228}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,370] Trial 217 finished with value: 0.5230574575761704 and parameters: {'x': 2.7422112563005983, 'y': -5.675723627822836}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,382] Trial 218 finished with value: 1.087258502014888 and parameters: {'x': 4.001619631023182, 'y': -4.710143799852629}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,385] Trial 219 finished with value: 0.5356427595754826 and parameters: {'x': 2.298078873771115, 'y': -5.207242592458829}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,385] Trial 220 finished with value: 1.4918345485530198 and parameters: {'x': 3.170388139307668, 'y': -3.790536304581121}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,403] Trial 221 finished with value: 273.19213331657375 and parameters: {'x': 3.256266673411505, 'y': 11.526538073918335}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,405] Trial 222 finished with value: 0.07161987935508539 and parameters: {'x': 2.933788443650986, 'y': -5.259298879983942}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,405] Trial 223 finished with value: 0.9491176236744563 and parameters: {'x': 2.7104503174445025, 'y': -5.930203528807791}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,422] Trial 224 finished with value: 0.8242785876091285 and parameters: {'x': 3.752502436166596, 'y': -4.4920446169470525}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,429] Trial 225 finished with value: 0.051871280295655 and parameters: {'x': 2.997645917784267, 'y': -5.227740507140422}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,434] Trial 226 finished with value: 0.5169703307733154 and parameters: {'x': 2.302891555916371, 'y': -5.176096984530165}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,436] Trial 227 finished with value: 1.4365898958664363 and parameters: {'x': 2.803456074449486, 'y': -6.182353746217954}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,449] Trial 228 finished with value: 1.9334198122340835 and parameters: {'x': 1.6675799789523922, 'y': -5.397588606156635}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,455] Trial 229 finished with value: 3.2686730554035504 and parameters: {'x': 2.9325810476395566, 'y': -6.806689718868785}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,457] Trial 230 finished with value: 30.184868083634232 and parameters: {'x': -2.4934901420854945, 'y': -4.919786893566453}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,469] Trial 231 finished with value: 49.462321327865524 and parameters: {'x': -4.00324858682565, 'y': -4.354375837665555}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,470] Trial 232 finished with value: 0.5093282514829465 and parameters: {'x': 3.209293824008525, 'y': -5.682293446190739}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,470] Trial 233 finished with value: 0.2873538690349661 and parameters: {'x': 3.509032050026886, 'y': -4.831951670402852}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,486] Trial 234 finished with value: 1.205297421819447 and parameters: {'x': 2.561762253909084, 'y': -3.993399235187753}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,489] Trial 235 finished with value: 0.14473293473097718 and parameters: {'x': 3.0812347389749726, 'y': -5.371663627376483}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,489] Trial 236 finished with value: 2.2546287478779865 and parameters: {'x': 2.2041593177876324, 'y': -6.273289580737131}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,507] Trial 237 finished with value: 0.2576436122852226 and parameters: {'x': 3.0063891166463366, 'y': -5.5075458515973725}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,507] Trial 238 finished with value: 0.15981591391745556 and parameters: {'x': 2.653156552853784, 'y': -5.19878515309043}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,521] Trial 239 finished with value: 0.16378243596403483 and parameters: {'x': 2.599671821322687, 'y': -4.940672221338228}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,521] Trial 240 finished with value: 0.23946168554559902 and parameters: {'x': 2.5182890111970018, 'y': -5.086117412943241}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,521] Trial 241 finished with value: 0.3986458010049727 and parameters: {'x': 2.6227649937465123, 'y': -4.493700137209278}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,536] Trial 242 finished with value: 0.15387429237084105 and parameters: {'x': 3.390349326364582, 'y': -5.038751719672268}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,536] Trial 243 finished with value: 1.081975140066613 and parameters: {'x': 3.4928275658551957, 'y': -5.916021904978181}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,552] Trial 244 finished with value: 0.871473948787254 and parameters: {'x': 2.076190728117914, 'y': -5.134351695084}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,552] Trial 245 finished with value: 0.8831921666167938 and parameters: {'x': 3.8033017023317486, 'y': -5.487748440948517}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,568] Trial 246 finished with value: 1.9741496853303744 and parameters: {'x': 3.305365002830891, 'y': -6.371459769871674}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,581] Trial 247 finished with value: 0.10826600259309876 and parameters: {'x': 2.685897255199719, 'y': -4.9019925089494265}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,592] Trial 248 finished with value: 0.6923912522446743 and parameters: {'x': 2.9059001129213238, 'y': -4.173237359639144}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,601] Trial 249 finished with value: 0.4448512054717603 and parameters: {'x': 2.3680028569781735, 'y': -4.786854939808568}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,608] Trial 250 finished with value: 0.9573630055602836 and parameters: {'x': 3.4449505417060786, 'y': -5.8714252813613745}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,608] Trial 251 finished with value: 2.7233214462890776 and parameters: {'x': 1.8730936470794015, 'y': -3.7944281365110277}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,624] Trial 252 finished with value: 1.2365707981701408 and parameters: {'x': 4.103163391307634, 'y': -4.859995249192103}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,624] Trial 253 finished with value: 0.5345473851789257 and parameters: {'x': 3.0423201166584506, 'y': -4.270098367651544}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,640] Trial 254 finished with value: 0.6055426232645423 and parameters: {'x': 2.6408148052494136, 'y': -5.690310523704025}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,640] Trial 255 finished with value: 0.6571264558534031 and parameters: {'x': 3.800488527615302, 'y': -5.127845895552766}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,655] Trial 256 finished with value: 1.8810348896765656 and parameters: {'x': 3.2501989100432933, 'y': -6.348493750482261}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,655] Trial 257 finished with value: 2.537376735476047 and parameters: {'x': 2.273539869380055, 'y': -3.5823849556047667}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,655] Trial 258 finished with value: 0.15875085464238328 and parameters: {'x': 2.784698022671565, 'y': -4.664745002720542}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,671] Trial 259 finished with value: 0.4700992326893765 and parameters: {'x': 2.8071051443431956, 'y': -5.657944380134459}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,671] Trial 260 finished with value: 0.37737335212376305 and parameters: {'x': 3.6096773148054617, 'y': -4.9247210259410705}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,687] Trial 261 finished with value: 0.9916852071203242 and parameters: {'x': 3.1662307179834612, 'y': -4.018138219748305}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,687] Trial 262 finished with value: 0.4347886897876828 and parameters: {'x': 2.393137123658704, 'y': -5.257887842106703}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,687] Trial 263 finished with value: 1.8353290634477535 and parameters: {'x': 1.7215932212518588, 'y': -4.55166399709754}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,707] Trial 264 finished with value: 8.014425365442168 and parameters: {'x': 4.313305372629309, 'y': -7.5079183327343735}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,707] Trial 265 finished with value: 1.879305342362806 and parameters: {'x': 2.9311380706818873, 'y': -6.369146952322282}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,721] Trial 266 finished with value: 3.30562260464428 and parameters: {'x': 3.410646509809997, 'y': -3.2288444312751214}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,727] Trial 267 finished with value: 385.0635374636145 and parameters: {'x': 2.049648680326874, 'y': 14.600009434508191}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,727] Trial 268 finished with value: 0.7195240439071177 and parameters: {'x': 2.582853859108734, 'y': -5.738588614214057}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,737] Trial 269 finished with value: 1.0044231123789125 and parameters: {'x': 3.707330212286462, 'y': -4.289995011872662}. Best is trial 162 with value: 0.012144058631626434.\n",
      "[I 2025-08-11 10:21:09,737] Trial 270 finished with value: 0.01064000413972929 and parameters: {'x': 3.1022832535517906, 'y': -5.013346916594832}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,757] Trial 271 finished with value: 0.0882682936555864 and parameters: {'x': 2.7087958075330034, 'y': -4.941106775048136}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,757] Trial 272 finished with value: 0.07419248904153311 and parameters: {'x': 2.989693459540729, 'y': -4.727812079134113}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,773] Trial 273 finished with value: 2.1838232832345827 and parameters: {'x': 2.2124730861956516, 'y': -3.749550223612167}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,773] Trial 274 finished with value: 0.23721393271770103 and parameters: {'x': 2.996639319028827, 'y': -4.512965464734675}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,785] Trial 275 finished with value: 18.742007278412448 and parameters: {'x': -1.318498260415366, 'y': -4.695730295293952}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,785] Trial 276 finished with value: 2.665595287269104 and parameters: {'x': 2.7643095832872207, 'y': -3.3844365333609265}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,785] Trial 277 finished with value: 3.4193627906768733 and parameters: {'x': 2.3208359561290997, 'y': -6.71991249550371}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,803] Trial 278 finished with value: 49.76342911098635 and parameters: {'x': 3.077678638815772, 'y': 2.0538921979328606}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,803] Trial 279 finished with value: 1.1569462828139376 and parameters: {'x': 2.588319650005335, 'y': -5.993713023081718}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,820] Trial 280 finished with value: 3.4141193666279555 and parameters: {'x': 1.3757536347617239, 'y': -4.119123668363031}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,822] Trial 281 finished with value: 1.4925839938059 and parameters: {'x': 1.8044903580775928, 'y': -4.748324236612943}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,822] Trial 282 finished with value: 1.215417241028123 and parameters: {'x': 3.889859517167192, 'y': -5.650820467360312}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,837] Trial 283 finished with value: 0.7472726818116631 and parameters: {'x': 3.0475725496365333, 'y': -4.136860651845403}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,837] Trial 284 finished with value: 5.586113724876464 and parameters: {'x': 2.0609143438276796, 'y': -2.831075876097122}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,853] Trial 285 finished with value: 0.2388659446449073 and parameters: {'x': 3.4262024549825134, 'y': -5.239201613731567}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,857] Trial 286 finished with value: 0.31506446609782274 and parameters: {'x': 2.4646914204807606, 'y': -4.831153351259443}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,857] Trial 287 finished with value: 1.185706325829485 and parameters: {'x': 2.812994775110732, 'y': -6.072723343501762}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,874] Trial 288 finished with value: 3.9768266247509922 and parameters: {'x': 3.219449198408219, 'y': -6.982086949169734}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,880] Trial 289 finished with value: 0.8444625220615475 and parameters: {'x': 3.7253181827808906, 'y': -5.564248221786276}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,891] Trial 290 finished with value: 1.6740291732723949 and parameters: {'x': 2.760491505614384, 'y': -3.7285186378127557}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,897] Trial 291 finished with value: 138.08856071551745 and parameters: {'x': -8.750125818656521, 'y': -4.848000127437949}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,905] Trial 292 finished with value: 1.0474349675368524 and parameters: {'x': 2.2554435978160305, 'y': -4.297810045996302}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,911] Trial 293 finished with value: 29.153695980712325 and parameters: {'x': 4.081698674032658, 'y': 0.28995500541434843}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,911] Trial 294 finished with value: 0.14833230483184015 and parameters: {'x': 3.178979086756007, 'y': -5.341026086004907}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,925] Trial 295 finished with value: 1.590158541667803 and parameters: {'x': 3.4964916384875675, 'y': -6.1591611598823235}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,925] Trial 296 finished with value: 0.26767981560356585 and parameters: {'x': 3.1159335546212357, 'y': -5.504221406245759}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,942] Trial 297 finished with value: 0.5085373298049515 and parameters: {'x': 3.587424231075522, 'y': -5.40431436104878}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,942] Trial 298 finished with value: 2.5421573698010214 and parameters: {'x': 2.9874727005013524, 'y': -6.594365214299501}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,955] Trial 299 finished with value: 2.578450627472684 and parameters: {'x': 4.540296158045814, 'y': -4.546195666633748}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,963] Trial 300 finished with value: 163.25692581272537 and parameters: {'x': 3.238511285369466, 'y': 7.774977032444199}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,969] Trial 301 finished with value: 1.9285819482580115 and parameters: {'x': 3.9472363251529137, 'y': -6.0155418714010835}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,977] Trial 302 finished with value: 2.4481649534789294 and parameters: {'x': 2.6608744561923903, 'y': -3.4725318926353577}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,983] Trial 303 finished with value: 107.09373194337851 and parameters: {'x': 1.9969296553360203, 'y': 5.2998826122938985}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:09,991] Trial 304 finished with value: 0.20797820921834576 and parameters: {'x': 3.4151777743280745, 'y': -5.188694528066747}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,007] Trial 305 finished with value: 0.8733860325873677 and parameters: {'x': 2.9453435590760675, 'y': -4.067048390294064}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,021] Trial 306 finished with value: 0.4130033216563055 and parameters: {'x': 2.372586091170697, 'y': -4.86087736106643}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,030] Trial 307 finished with value: 0.6471847220859827 and parameters: {'x': 2.79016006616612, 'y': -5.7766285626054295}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,036] Trial 308 finished with value: 0.8910147049106718 and parameters: {'x': 3.720911435354557, 'y': -4.390654935782931}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,036] Trial 309 finished with value: 6.693630945805125 and parameters: {'x': 3.2264480231643247, 'y': -2.4227238722616287}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,052] Trial 310 finished with value: 11.598615167605551 and parameters: {'x': 4.209609843840478, 'y': -8.183623594787827}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,060] Trial 311 finished with value: 1.7490416443539103 and parameters: {'x': 1.6991123328828908, 'y': -5.238186737448825}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,069] Trial 312 finished with value: 4.873572057392127 and parameters: {'x': 2.367281219250403, 'y': -7.1150033101342585}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,074] Trial 313 finished with value: 1.960868874361785 and parameters: {'x': 2.8813905081246767, 'y': -6.395277987642198}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,074] Trial 314 finished with value: 49.771154858648586 and parameters: {'x': 3.4922493171261415, 'y': -12.037673299353802}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,086] Trial 315 finished with value: 0.7355794191787373 and parameters: {'x': 2.546326218341376, 'y': -5.727845807169555}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,086] Trial 316 finished with value: 2.4031162277711324 and parameters: {'x': 2.0042040757635897, 'y': -3.8119315234190894}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,103] Trial 317 finished with value: 0.10237571435936059 and parameters: {'x': 3.15914805853311, 'y': -4.722425487797416}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,103] Trial 318 finished with value: 3.452746125226348 and parameters: {'x': 3.791297121335762, 'y': -3.3187519543529325}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,103] Trial 319 finished with value: 18.588640876909817 and parameters: {'x': 7.257561739751526, 'y': -4.320434764637142}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,123] Trial 320 finished with value: 3.434784318414383 and parameters: {'x': 4.827897657524461, 'y': -4.694100552418002}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,123] Trial 321 finished with value: 0.052468900050953365 and parameters: {'x': 3.175648327317743, 'y': -4.852974270410134}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,138] Trial 322 finished with value: 0.7903851665156387 and parameters: {'x': 3.2623908534729726, 'y': -5.849432873468742}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,140] Trial 323 finished with value: 1.2800072905507507 and parameters: {'x': 4.110250949230587, 'y': -5.217600827855343}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,153] Trial 324 finished with value: 1.4056493986176894 and parameters: {'x': 3.5784296956478308, 'y': -3.965075613481619}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,153] Trial 325 finished with value: 1.7992190457325994 and parameters: {'x': 3.1541607808042915, 'y': -6.332461443867856}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,153] Trial 326 finished with value: 0.06833316404999026 and parameters: {'x': 3.151254401432838, 'y': -4.786797584213536}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,169] Trial 327 finished with value: 0.42603442551119014 and parameters: {'x': 3.0223238268146915, 'y': -4.347668740387571}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,169] Trial 328 finished with value: 3.319851400162069 and parameters: {'x': 2.3360506383526154, 'y': -3.3032317054676854}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,188] Trial 329 finished with value: 0.7103116262317795 and parameters: {'x': 3.7169094471898743, 'y': -5.443116768766076}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,194] Trial 330 finished with value: 0.0457598373745292 and parameters: {'x': 2.989182076238351, 'y': -4.786358220612128}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,202] Trial 331 finished with value: 1.3252430691996158 and parameters: {'x': 2.7661838673339836, 'y': -3.8728029962314823}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,203] Trial 332 finished with value: 0.7768563619928465 and parameters: {'x': 2.2115448511964306, 'y': -4.606052236561765}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,203] Trial 333 finished with value: 83.4360003086607 and parameters: {'x': -6.1322945302195, 'y': -4.807134964330789}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,223] Trial 334 finished with value: 6.1512702062409215 and parameters: {'x': 1.4711579281910416, 'y': -3.04707600616209}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,223] Trial 335 finished with value: 0.8387723900935782 and parameters: {'x': 2.9448245353296105, 'y': -5.914181633042354}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,243] Trial 336 finished with value: 1.2673838512601143 and parameters: {'x': 2.565636333537392, 'y': -3.9613893624089562}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,252] Trial 337 finished with value: 0.18276356930130716 and parameters: {'x': 3.4177290698920344, 'y': -4.9090824908587845}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,258] Trial 338 finished with value: 2.931100787480122 and parameters: {'x': 3.01240350100978, 'y': -6.7120008588323845}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,269] Trial 339 finished with value: 1.2735676430146792 and parameters: {'x': 3.984518183762099, 'y': -4.448373687305929}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,277] Trial 340 finished with value: 1.6958566370926815 and parameters: {'x': 1.9209270495825297, 'y': -5.729011800158281}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,277] Trial 341 finished with value: 0.23598989802781833 and parameters: {'x': 2.525421308059344, 'y': -5.103754340553609}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,288] Trial 342 finished with value: 7.694643193791628 and parameters: {'x': 5.735031740233314, 'y': -4.537134389149552}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,288] Trial 343 finished with value: 1.9352550276330773 and parameters: {'x': 3.3945279505779364, 'y': -3.6659824874291003}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,305] Trial 344 finished with value: 14.940165278389633 and parameters: {'x': -0.7268357903480815, 'y': -6.025114759512428}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,305] Trial 345 finished with value: 0.18632055259660174 and parameters: {'x': 2.885378113115462, 'y': -5.416151866082119}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,322] Trial 346 finished with value: 1.3612309462052086 and parameters: {'x': 3.759105271993967, 'y': -4.114003311385322}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,323] Trial 347 finished with value: 7.320129903570113 and parameters: {'x': 4.336476093879093, 'y': -2.647562635465124}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,336] Trial 348 finished with value: 0.6386842415348069 and parameters: {'x': 2.237221416977478, 'y': -4.761561171750572}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,339] Trial 349 finished with value: 5.200237006941527 and parameters: {'x': 1.1093196140422654, 'y': -6.274976346877164}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,351] Trial 350 finished with value: 0.2791228900040032 and parameters: {'x': 3.158232586494688, 'y': -5.504068783575421}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,356] Trial 351 finished with value: 0.9766975220836815 and parameters: {'x': 2.6527838837147866, 'y': -4.074722479103975}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,356] Trial 352 finished with value: 5.388633211235645 and parameters: {'x': 3.2787675906837204, 'y': -7.304543738274464}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,369] Trial 353 finished with value: 0.37751283639979283 and parameters: {'x': 3.6126162380609825, 'y': -5.047055087544307}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,369] Trial 354 finished with value: 2.286102627386449 and parameters: {'x': 2.5275945069593866, 'y': -3.563707662928085}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,386] Trial 355 finished with value: 0.4203574207406641 and parameters: {'x': 2.948799363649069, 'y': -5.646324930339163}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,386] Trial 356 finished with value: 91.71652974781624 and parameters: {'x': 2.0258990987383023, 'y': -14.527206158259482}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,386] Trial 357 finished with value: 0.2954028745550458 and parameters: {'x': 3.1193720698998884, 'y': -4.469761201454607}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,402] Trial 358 finished with value: 0.17023273281517004 and parameters: {'x': 2.6110603501610243, 'y': -5.137690528353642}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,412] Trial 359 finished with value: 2.31383702998053 and parameters: {'x': 3.889100292516439, 'y': -6.234235674345752}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,420] Trial 360 finished with value: 0.5379398804493485 and parameters: {'x': 3.397987708539463, 'y': -4.383927224833903}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,436] Trial 361 finished with value: 3.1546004782626174 and parameters: {'x': 2.3105127605414615, 'y': -6.636828587508925}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,451] Trial 362 finished with value: 1.766884990790868 and parameters: {'x': 1.6709861078967336, 'y': -5.024638696950029}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,460] Trial 363 finished with value: 3.478624828486648 and parameters: {'x': 2.86520003107226, 'y': -3.13977049887286}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,471] Trial 364 finished with value: 0.6943393875008832 and parameters: {'x': 3.477860117754917, 'y': -5.682633939502088}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,472] Trial 365 finished with value: 29.500991056331127 and parameters: {'x': 2.971744635932075, 'y': -10.431407984190887}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,472] Trial 366 finished with value: 3.066708183456385 and parameters: {'x': 4.374825898973742, 'y': -3.915305604805009}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,487] Trial 367 finished with value: 0.5734165977690162 and parameters: {'x': 2.2802185097596954, 'y': -4.764774142415289}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,499] Trial 368 finished with value: 24.01491352448711 and parameters: {'x': -1.871584416595251, 'y': -5.531581410955478}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,503] Trial 369 finished with value: 1.095255455294674 and parameters: {'x': 3.8065507946291985, 'y': -4.333118248129638}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,503] Trial 370 finished with value: 0.11114456342308487 and parameters: {'x': 2.673286161615776, 'y': -5.066352326495248}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,522] Trial 371 finished with value: 1.9266322081399876 and parameters: {'x': 1.9262668058703762, 'y': -5.879618801506757}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,524] Trial 372 finished with value: 3.042126254256605 and parameters: {'x': 2.5858922537346394, 'y': -6.69429661769704}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,536] Trial 373 finished with value: 0.06620414098203908 and parameters: {'x': 3.218600780477073, 'y': -5.13571234194742}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,543] Trial 374 finished with value: 35.19591398522819 and parameters: {'x': 8.932384555116613, 'y': -4.94777476240312}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,550] Trial 375 finished with value: 2.2284732554408233 and parameters: {'x': 3.3895864422569777, 'y': -3.5589255191176363}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,559] Trial 376 finished with value: 1.3295636165646727 and parameters: {'x': 2.6196624440436063, 'y': -6.088534317370743}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,566] Trial 377 finished with value: 1.0541831481889923 and parameters: {'x': 4.018856181541228, 'y': -5.126945773951797}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,569] Trial 378 finished with value: 72.87101935476568 and parameters: {'x': 3.1217790755732944, 'y': -13.535583706549787}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,582] Trial 379 finished with value: 1.1180405557804876 and parameters: {'x': 2.190274753112949, 'y': -4.320010602778108}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,586] Trial 380 finished with value: 0.3585788337062158 and parameters: {'x': 3.584591634249027, 'y': -4.870263902971195}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,597] Trial 381 finished with value: 348.3894572822255 and parameters: {'x': 2.7231238981156403, 'y': 13.66314006019434}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,602] Trial 382 finished with value: 0.25743899036951773 and parameters: {'x': 3.266533883726433, 'y': -5.431739133268253}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,602] Trial 383 finished with value: 1.1264478454386246 and parameters: {'x': 2.9237299309580114, 'y': -3.941401529376244}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,620] Trial 384 finished with value: 10.185083729458961 and parameters: {'x': 2.34436351863277, 'y': -1.8766645178976757}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,622] Trial 385 finished with value: 3.5386283118110455 and parameters: {'x': 1.4134637822824772, 'y': -6.010708237663878}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,622] Trial 386 finished with value: 37.1323992290926 and parameters: {'x': 3.7060814600114775, 'y': 1.0525902059300742}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,641] Trial 387 finished with value: 18.360507405376858 and parameters: {'x': 1.8300099350177532, 'y': -0.8779094317058372}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,641] Trial 388 finished with value: 0.2351905351982442 and parameters: {'x': 3.180776735098185, 'y': -4.549988547650746}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,653] Trial 389 finished with value: 0.2759657288455855 and parameters: {'x': 2.6202104759971774, 'y': -5.36294027925169}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,653] Trial 390 finished with value: 3.7966736180833247 and parameters: {'x': 4.184901838724695, 'y': -3.453170581263027}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,653] Trial 391 finished with value: 2.8865174386100003 and parameters: {'x': 3.4960490120997445, 'y': -6.624947019507057}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,668] Trial 392 finished with value: 0.589461048104602 and parameters: {'x': 2.918391333942326, 'y': -4.236585909398517}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,668] Trial 393 finished with value: 0.6431750075504299 and parameters: {'x': 2.2048708508502832, 'y': -4.895383348730341}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,684] Trial 394 finished with value: 0.7361981666365172 and parameters: {'x': 2.551347165389228, 'y': -5.731374596654981}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,684] Trial 395 finished with value: 4.469144922068845 and parameters: {'x': 3.217155738832293, 'y': -2.897147578368599}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,706] Trial 396 finished with value: 6.1150183389762045 and parameters: {'x': 3.7621247747988833, 'y': -7.352484679357967}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,706] Trial 397 finished with value: 0.042784176296954815 and parameters: {'x': 2.8348126009262855, 'y': -4.875511850024927}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,720] Trial 398 finished with value: 0.10567229063440932 and parameters: {'x': 2.9290964101483765, 'y': -5.317245916570351}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,722] Trial 399 finished with value: 5.96157177129148 and parameters: {'x': 5.098007070121335, 'y': -6.2489748216086545}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,734] Trial 400 finished with value: 2.6677540369619237 and parameters: {'x': 4.54372687293359, 'y': -4.466463329522137}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,737] Trial 401 finished with value: 1.3402900338565351 and parameters: {'x': 3.2841384722202607, 'y': -3.877700858745374}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,737] Trial 402 finished with value: 1.367312407395545 and parameters: {'x': 4.072028284837706, 'y': -5.466977262726433}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,753] Trial 403 finished with value: 13.664989261300748 and parameters: {'x': 6.695601251411523, 'y': -5.08672169201726}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,764] Trial 404 finished with value: 0.9612713702898689 and parameters: {'x': 2.9409764203515265, 'y': -5.978666228770233}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,773] Trial 405 finished with value: 0.5686988341548401 and parameters: {'x': 3.5726854307672866, 'y': -4.509357328046441}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,773] Trial 406 finished with value: 4.105418919870371 and parameters: {'x': 2.3279565016898696, 'y': -6.911485405711865}. Best is trial 270 with value: 0.01064000413972929.\n",
      "[I 2025-08-11 10:21:10,788] Trial 407 finished with value: 0.008187081099122456 and parameters: {'x': 2.9222175482684034, 'y': -5.046227386923168}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,788] Trial 408 finished with value: 1.3527355558087795 and parameters: {'x': 3.18795901359299, 'y': -3.8522164990652943}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,804] Trial 409 finished with value: 0.8702589210488286 and parameters: {'x': 3.784528718115215, 'y': -5.504751039128525}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,810] Trial 410 finished with value: 0.2747357401026837 and parameters: {'x': 3.4070514760073, 'y': -4.669780624458585}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,825] Trial 411 finished with value: 8.243944998458932 and parameters: {'x': 2.9432072510354157, 'y': -7.8706653553007495}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,848] Trial 412 finished with value: 2.3882094454489966 and parameters: {'x': 2.104237557549341, 'y': -6.259293092232236}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,862] Trial 413 finished with value: 3.1947764069643307 and parameters: {'x': 2.859536612408074, 'y': -3.2181339995076703}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,871] Trial 414 finished with value: 1.1160568650256817 and parameters: {'x': 3.6151630928680873, 'y': -4.141145394028389}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,871] Trial 415 finished with value: 0.4393345952243945 and parameters: {'x': 3.217353044987049, 'y': -5.626172699068917}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,887] Trial 416 finished with value: 1.0190443797219502 and parameters: {'x': 4.009467808818277, 'y': -4.995627051157794}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,887] Trial 417 finished with value: 0.5205560320809954 and parameters: {'x': 2.459571813555745, 'y': -4.5219901597481815}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,887] Trial 418 finished with value: 0.6718377154908696 and parameters: {'x': 2.867694141282142, 'y': -5.808908446760077}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,903] Trial 419 finished with value: 2.4505444785242347 and parameters: {'x': 1.9231505990869302, 'y': -3.863804661918824}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,903] Trial 420 finished with value: 0.13014884052427075 and parameters: {'x': 3.3501333379722475, 'y': -5.086922299582343}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,919] Trial 421 finished with value: 2.1522516842945265 and parameters: {'x': 2.5842039184173413, 'y': -6.406899180053437}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,919] Trial 422 finished with value: 0.18107508566395503 and parameters: {'x': 3.0532437490457394, 'y': -5.422185017322393}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,939] Trial 423 finished with value: 0.651033826515255 and parameters: {'x': 3.704580227581644, 'y': -4.606807261745269}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,939] Trial 424 finished with value: 3.957544249330776 and parameters: {'x': 4.408724514681699, 'y': -3.5953507587067914}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,954] Trial 425 finished with value: 6.638047000403844 and parameters: {'x': 2.33217565905553, 'y': -2.51161545374395}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,954] Trial 426 finished with value: 219.15048883026336 and parameters: {'x': 3.371659175237215, 'y': 9.799066128905748}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,954] Trial 427 finished with value: 96.17280399356943 and parameters: {'x': 7.960093245069187, 'y': 3.4599219259865768}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,970] Trial 428 finished with value: 0.6386761146179772 and parameters: {'x': 2.854063705509429, 'y': -5.78573450514047}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,970] Trial 429 finished with value: 1.9298791812013192 and parameters: {'x': 1.6221631232572462, 'y': -4.82267340219501}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,986] Trial 430 finished with value: 16.690646691808947 and parameters: {'x': 2.5843903528589993, 'y': -9.064223826638031}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:10,986] Trial 431 finished with value: 5.214469475245701 and parameters: {'x': 0.8140432811030682, 'y': -4.339649563977534}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,002] Trial 432 finished with value: 0.20325495370052976 and parameters: {'x': 3.140238809536704, 'y': -5.428471737691365}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,002] Trial 433 finished with value: 4.315397905616588 and parameters: {'x': 3.927798671164137, 'y': -6.858652073789672}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,022] Trial 434 finished with value: 1.3284432694846187 and parameters: {'x': 2.214808723583153, 'y': -4.156247708789184}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,022] Trial 435 finished with value: 1.3835675105320882 and parameters: {'x': 3.5168663240477778, 'y': -6.056606224474106}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,037] Trial 436 finished with value: 0.034725623358527954 and parameters: {'x': 2.8138837378410737, 'y': -5.009293025261871}. Best is trial 407 with value: 0.008187081099122456.\n",
      "[I 2025-08-11 10:21:11,038] Trial 437 finished with value: 0.003361844368758654 and parameters: {'x': 3.0417248993211032, 'y': -5.040260118546801}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,038] Trial 438 finished with value: 1.5276363108621092 and parameters: {'x': 4.2004683760867465, 'y': -5.29412920439453}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,054] Trial 439 finished with value: 1.586028852941881 and parameters: {'x': 3.1326769839390387, 'y': -6.252368025332299}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,054] Trial 440 finished with value: 3.1177059573710517 and parameters: {'x': 4.764788610793716, 'y': -5.0568077158829405}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,070] Trial 441 finished with value: 0.7840460314328088 and parameters: {'x': 3.6404402566301854, 'y': -5.61145916390244}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,070] Trial 442 finished with value: 0.9438135715249886 and parameters: {'x': 3.0630706140277195, 'y': -4.030548779375076}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,084] Trial 443 finished with value: 0.3112263216448223 and parameters: {'x': 3.4551369053540966, 'y': -4.67739076419061}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,086] Trial 444 finished with value: 3.367235303852534 and parameters: {'x': 2.7020647778861377, 'y': -6.8106545521651825}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,086] Trial 445 finished with value: 1.5781328798208587 and parameters: {'x': 3.936164988075671, 'y': -5.837692064497532}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,102] Trial 446 finished with value: 39.37420409235566 and parameters: {'x': -3.0980667962995865, 'y': -3.520883560964803}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,102] Trial 447 finished with value: 0.00873663775654127 and parameters: {'x': 3.046056930151129, 'y': -5.0813350904689685}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,118] Trial 448 finished with value: 0.6931611682124507 and parameters: {'x': 3.4832401223332856, 'y': -4.322032336774266}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,118] Trial 449 finished with value: 23.421742220490703 and parameters: {'x': 2.4037251450920913, 'y': -0.1972717630605768}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,137] Trial 450 finished with value: 0.08089047227059526 and parameters: {'x': 3.192952207006579, 'y': -4.791050441297701}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,138] Trial 451 finished with value: 2.7603325146555138 and parameters: {'x': 1.983003661696119, 'y': -6.3137925873333325}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,138] Trial 452 finished with value: 11.537507414431204 and parameters: {'x': 0.0963401052290842, 'y': -3.2375396089755215}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,154] Trial 453 finished with value: 0.7860468628039319 and parameters: {'x': 3.881048393699406, 'y': -5.098997933128064}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,154] Trial 454 finished with value: 42.08261497125316 and parameters: {'x': 2.8314932020660963, 'y': -11.484922546206949}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,170] Trial 455 finished with value: 0.8300059842897077 and parameters: {'x': 3.332931952112422, 'y': -4.151965625960646}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,170] Trial 456 finished with value: 1.0130992942624708 and parameters: {'x': 2.418056178208356, 'y': -5.821243375949545}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,186] Trial 457 finished with value: 0.009844337930973706 and parameters: {'x': 3.0672145245526585, 'y': -4.927016812757089}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,186] Trial 458 finished with value: 0.43538248487360576 and parameters: {'x': 3.6213966493209164, 'y': -4.7780795433351315}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,202] Trial 459 finished with value: 1.5408008031160871 and parameters: {'x': 3.1270212255719243, 'y': -3.765226169952451}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,202] Trial 460 finished with value: 2.2693920203097684 and parameters: {'x': 4.373091905232361, 'y': -4.380314079476438}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,225] Trial 461 finished with value: 0.08170164034621775 and parameters: {'x': 2.7165552837603566, 'y': -5.036888117084581}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,239] Trial 462 finished with value: 0.35814463128935514 and parameters: {'x': 3.385984236314395, 'y': -5.457341011288238}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,249] Trial 463 finished with value: 0.6971834890566688 and parameters: {'x': 3.8296809898438364, 'y': -4.906122717612723}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,260] Trial 464 finished with value: 1.258028573999723 and parameters: {'x': 2.6452774186161414, 'y': -6.0640490892135075}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,268] Trial 465 finished with value: 4.0844845352631385 and parameters: {'x': 2.0759497403579834, 'y': -3.202608653376049}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,275] Trial 466 finished with value: 56.06781122757599 and parameters: {'x': -4.068853666707125, 'y': -7.469639460783138}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,285] Trial 467 finished with value: 0.7631026996013334 and parameters: {'x': 3.0974618977950152, 'y': -4.131896389778543}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,296] Trial 468 finished with value: 0.41576231492724375 and parameters: {'x': 2.46264315504039, 'y': -5.356384534039144}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,306] Trial 469 finished with value: 1.346297779949285 and parameters: {'x': 4.0840076450905505, 'y': -4.586206325163706}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,313] Trial 470 finished with value: 2.6283290335998 and parameters: {'x': 2.952929540063234, 'y': -6.620528742540885}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,319] Trial 471 finished with value: 1.8992521879975848 and parameters: {'x': 3.5570914975266685, 'y': -3.739483736169549}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,319] Trial 472 finished with value: 2.1237355471119708 and parameters: {'x': 1.7769083301375468, 'y': -5.792327151008374}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,335] Trial 473 finished with value: 0.07369526414577338 and parameters: {'x': 3.2610290143693517, 'y': -5.0745594917038614}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,335] Trial 474 finished with value: 0.10866092837688748 and parameters: {'x': 2.766704658935195, 'y': -5.232882399966901}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,351] Trial 475 finished with value: 65.35646089354604 and parameters: {'x': -5.074088799683447, 'y': -4.593120474375598}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,351] Trial 476 finished with value: 1.495684156924122 and parameters: {'x': 2.302135371820238, 'y': -6.0043252051301135}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,351] Trial 477 finished with value: 5.797800324826811 and parameters: {'x': 3.2308713193445247, 'y': -2.6032316009403558}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,368] Trial 478 finished with value: 1.094000119994368 and parameters: {'x': 3.736179524917841, 'y': -4.257006172915205}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,368] Trial 479 finished with value: 0.16730151421021924 and parameters: {'x': 2.791057658726445, 'y': -5.3516313584328685}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,388] Trial 480 finished with value: 0.11528553198380198 and parameters: {'x': 3.3299552367562106, 'y': -4.9199058446517165}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,391] Trial 481 finished with value: 2.5602701685529476 and parameters: {'x': 2.5369901244990856, 'y': -3.4683694885052807}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,402] Trial 482 finished with value: 1.591540209060058 and parameters: {'x': 2.987893227614663, 'y': -6.261504512525606}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,402] Trial 483 finished with value: 2.645509236308353 and parameters: {'x': 1.5269377480009612, 'y': -5.689635293502206}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,416] Trial 484 finished with value: 2.158382709847301 and parameters: {'x': 4.199013869421023, 'y': -4.151030948277072}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,416] Trial 485 finished with value: 0.9155747568896169 and parameters: {'x': 2.0762785668540333, 'y': -4.750373337088407}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,432] Trial 486 finished with value: 3.7010589692346474 and parameters: {'x': 3.560368970328424, 'y': -6.8403927804487035}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,432] Trial 487 finished with value: 0.07592220933589544 and parameters: {'x': 3.086487062070783, 'y': -5.261614597127645}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,448] Trial 488 finished with value: 10.896837565353891 and parameters: {'x': 6.250643270203476, 'y': -5.574591938017534}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,448] Trial 489 finished with value: 140.15566537090484 and parameters: {'x': 3.276533956720799, 'y': 6.835505664807278}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,448] Trial 490 finished with value: 1.4494083034814937 and parameters: {'x': 3.7922305755076486, 'y': -4.0934797196354}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,464] Trial 491 finished with value: 1.81359429499341 and parameters: {'x': 3.0254140137157064, 'y': -6.34645773156838}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,464] Trial 492 finished with value: 49.01857368998653 and parameters: {'x': 9.989849141699004, 'y': -5.400727670963998}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,480] Trial 493 finished with value: 0.27903673747190433 and parameters: {'x': 3.4419606449441162, 'y': -4.710677470990444}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,486] Trial 494 finished with value: 1.096163840546967 and parameters: {'x': 2.3614195509031806, 'y': -5.829685995168215}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,499] Trial 495 finished with value: 9.707658658609574 and parameters: {'x': 5.24959744835299, 'y': -7.15568318149335}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,508] Trial 496 finished with value: 2.713782741621234 and parameters: {'x': 3.96438113625121, 'y': -3.6644283000662004}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,511] Trial 497 finished with value: 2.996308629298457 and parameters: {'x': 4.677150198964661, 'y': -4.571659201789912}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,511] Trial 498 finished with value: 4.129102116783794 and parameters: {'x': 3.085087766580982, 'y': -2.9697630215262913}. Best is trial 437 with value: 0.003361844368758654.\n",
      "[I 2025-08-11 10:21:11,530] Trial 499 finished with value: 0.08646091122429415 and parameters: {'x': 2.748014089276396, 'y': -5.151538813579525}. Best is trial 437 with value: 0.003361844368758654.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# 목적 함수 \n",
    "def objective(trial) : \n",
    "    x = trial.suggest_uniform('x', -10, 10)   # 목적함수 안쪽에 범위 정의 \n",
    "    y = trial.suggest_uniform('y', -15, 15)\n",
    "    return (x - 3) ** 2 + (y + 5) ** 2\n",
    "\n",
    "# 스터디 생성\n",
    "study = optuna.create_study(direction='minimize')  # direction을 최소화 시키는 방향으로 최적화를 진행함\n",
    "\n",
    "# 최적화 실행\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffb46076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003361844368758654"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cf9f966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 3.0417248993211032, 'y': -5.040260118546801}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5526c02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "x (FloatDistribution): 0.06866844305829328<extra></extra>",
          "y (FloatDistribution): 0.9313315569417067<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.07",
          "0.93"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.06866844305829328,
          0.9313315569417067
         ],
         "y": [
          "x",
          "y"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "vis.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdb492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          208.09434365760814,
          10.675579272058835,
          377.87165820473416,
          135.5760108598713,
          240.08969997581355,
          130.9176055242644,
          520.7021358507079,
          62.719756868126616,
          95.20525134960555,
          145.2484800538277,
          41.792539332894826,
          46.15158266380369,
          49.088201493593104,
          7.753896446353136,
          16.975273402982403,
          23.41469773317407,
          24.01221298224064,
          23.615381044093056,
          5.219549435695668,
          96.47053591997887,
          34.350155951990274,
          23.923703783174304,
          8.87587196148534,
          6.410644490985147,
          41.34022580105952,
          51.74729282334618,
          28.333235244828337,
          25.34782503760715,
          42.32079329407819,
          65.20146775798867,
          6.904306388323533,
          5.405272299308319,
          23.51579701083545,
          157.50020321021947,
          26.74434836503989,
          7.281438066861374,
          39.769162791825295,
          29.27018000762431,
          61.32407785445696,
          8.190505765027464,
          98.80911333084919,
          6.363323154995639,
          1.9372619836762968,
          14.097147903833726,
          0.6770310225888577,
          17.00052652174787,
          2.409350924283244,
          16.930112824932422,
          2.3059738171594306,
          119.4011275845031,
          8.944307506753205,
          2.2351779405796535,
          1.1182039051981936,
          0.9863956376393622,
          8.504768537107257,
          16.932095169715023,
          4.194182038155686,
          21.710308696337307,
          9.071240931395389,
          355.6369652808205,
          12.552640516724324,
          1.9371730635543696,
          2.9908757911843806,
          9.530162430270792,
          28.64644007391385,
          4.317841292164291,
          49.75623591766018,
          14.070806206667365,
          10.003939290962705,
          33.41480625451293,
          0.7821874630497485,
          1.1106992966864264,
          1.3066408888660528,
          1.9282021905451345,
          11.814410121582469,
          2.2188764676404524,
          10.32934838147224,
          130.28338377158678,
          32.74237631003048,
          10.218254168501405,
          1.767004031291252,
          2.2327151249821533,
          11.40212889920064,
          23.414667760193787,
          32.84756701169124,
          7.8974216579033,
          6.998866522582264,
          0.9537006416778282,
          4.437296840876181,
          198.1645117261492,
          0.03277009101774215,
          0.41131398419434667,
          0.23427840304653805,
          0.02161324615668983,
          0.3503584543690087,
          4.282190009660603,
          0.32094561030299923,
          2.661333561474395,
          177.34843924135185,
          0.32612296547061087,
          3.809902379063222,
          6.474981322619662,
          2.145571057437735,
          19.138594887602476,
          5.872519704553597,
          6.144711451030268,
          1.0588109700176491,
          3.9014715528744577,
          2.5922233556575787,
          11.58864863603901,
          12.328698098250296,
          1.11420877792711,
          6.779739812606392,
          0.26409098954028815,
          7.328692487358934,
          2.996653655844339,
          77.0317114097123,
          0.3291320601221626,
          16.375279302024595,
          0.9492832658016664,
          0.8793416265834868,
          0.536225689800907,
          3.7647958115497513,
          0.5156011752786605,
          2.1765381238892787,
          7.288929169549953,
          5.961025369537106,
          6.238766390576162,
          3.478932144799133,
          0.36727970395553783,
          3.3643877118577747,
          0.030560058466445512,
          0.19473872082275206,
          0.2685768828610897,
          5.746064873109109,
          1.4191165007234359,
          2.9756273148097643,
          1.3678797415137227,
          1.012377477820858,
          10.465143667286142,
          2.3258146155390214,
          0.4614231973073656,
          0.13830664672954707,
          0.030855117977220205,
          2.5139534258288765,
          0.4998920412602532,
          1.0527527761352606,
          3.13258476683286,
          0.6946714084005761,
          4.909032849683399,
          82.8894438959642,
          0.21215236144583832,
          0.10606264482683012,
          0.8070358438296554,
          1.7342104501479507,
          0.14595738461448576,
          4.487848236328723,
          65.13072591471291,
          3.0572969977541224,
          5.294316970733727,
          1.1080666879963854,
          0.2853232611274318,
          0.012144058631626434,
          0.35365286297621334,
          0.16586964059103404,
          1.8528491290116944,
          0.8398639987274523,
          1.615859355660634,
          2.9287980838955656,
          0.7479158374168446,
          4.758401789984541,
          0.5158305367114702,
          0.6202142115440061,
          1.0298437090889236,
          0.11482054218094725,
          0.09415398511453095,
          1.198290968191392,
          1.9594178039710881,
          41.73730764822663,
          1.1134948809180372,
          0.07506258595750251,
          0.030822845364913913,
          0.2263431646045676,
          0.390571041109617,
          1.8755080450275678,
          4.866201827911841,
          2.1402108477250508,
          0.6334156648977944,
          1.0960270823935865,
          0.4890806465115392,
          1.3988198884563492,
          0.24523536052139827,
          0.08609222558212345,
          0.18529737779493594,
          0.7634365718286534,
          2.4117822665356696,
          3.735104271253333,
          0.28844154662401933,
          0.9437814107120359,
          0.8494633790768895,
          2.6990471979458817,
          0.014626104379835502,
          0.16815071302502446,
          0.2444838218457237,
          1.1898049092822711,
          1.3693959441555137,
          0.30731265499514787,
          0.2203671680040794,
          2.9366303024211615,
          1.2869150730615289,
          109.87947671822783,
          0.28470122276943455,
          0.352754593014865,
          0.4041440469736131,
          1.4457262405257527,
          0.9543866255243024,
          4.373913958137341,
          0.5230574575761704,
          1.087258502014888,
          0.5356427595754826,
          1.4918345485530198,
          273.19213331657375,
          0.07161987935508539,
          0.9491176236744563,
          0.8242785876091285,
          0.051871280295655,
          0.5169703307733154,
          1.4365898958664363,
          1.9334198122340835,
          3.2686730554035504,
          30.184868083634232,
          49.462321327865524,
          0.5093282514829465,
          0.2873538690349661,
          1.205297421819447,
          0.14473293473097718,
          2.2546287478779865,
          0.2576436122852226,
          0.15981591391745556,
          0.16378243596403483,
          0.23946168554559902,
          0.3986458010049727,
          0.15387429237084105,
          1.081975140066613,
          0.871473948787254,
          0.8831921666167938,
          1.9741496853303744,
          0.10826600259309876,
          0.6923912522446743,
          0.4448512054717603,
          0.9573630055602836,
          2.7233214462890776,
          1.2365707981701408,
          0.5345473851789257,
          0.6055426232645423,
          0.6571264558534031,
          1.8810348896765656,
          2.537376735476047,
          0.15875085464238328,
          0.4700992326893765,
          0.37737335212376305,
          0.9916852071203242,
          0.4347886897876828,
          1.8353290634477535,
          8.014425365442168,
          1.879305342362806,
          3.30562260464428,
          385.0635374636145,
          0.7195240439071177,
          1.0044231123789125,
          0.01064000413972929,
          0.0882682936555864,
          0.07419248904153311,
          2.1838232832345827,
          0.23721393271770103,
          18.742007278412448,
          2.665595287269104,
          3.4193627906768733,
          49.76342911098635,
          1.1569462828139376,
          3.4141193666279555,
          1.4925839938059,
          1.215417241028123,
          0.7472726818116631,
          5.586113724876464,
          0.2388659446449073,
          0.31506446609782274,
          1.185706325829485,
          3.9768266247509922,
          0.8444625220615475,
          1.6740291732723949,
          138.08856071551745,
          1.0474349675368524,
          29.153695980712325,
          0.14833230483184015,
          1.590158541667803,
          0.26767981560356585,
          0.5085373298049515,
          2.5421573698010214,
          2.578450627472684,
          163.25692581272537,
          1.9285819482580115,
          2.4481649534789294,
          107.09373194337851,
          0.20797820921834576,
          0.8733860325873677,
          0.4130033216563055,
          0.6471847220859827,
          0.8910147049106718,
          6.693630945805125,
          11.598615167605551,
          1.7490416443539103,
          4.873572057392127,
          1.960868874361785,
          49.771154858648586,
          0.7355794191787373,
          2.4031162277711324,
          0.10237571435936059,
          3.452746125226348,
          18.588640876909817,
          3.434784318414383,
          0.052468900050953365,
          0.7903851665156387,
          1.2800072905507507,
          1.4056493986176894,
          1.7992190457325994,
          0.06833316404999026,
          0.42603442551119014,
          3.319851400162069,
          0.7103116262317795,
          0.0457598373745292,
          1.3252430691996158,
          0.7768563619928465,
          83.4360003086607,
          6.1512702062409215,
          0.8387723900935782,
          1.2673838512601143,
          0.18276356930130716,
          2.931100787480122,
          1.2735676430146792,
          1.6958566370926815,
          0.23598989802781833,
          7.694643193791628,
          1.9352550276330773,
          14.940165278389633,
          0.18632055259660174,
          1.3612309462052086,
          7.320129903570113,
          0.6386842415348069,
          5.200237006941527,
          0.2791228900040032,
          0.9766975220836815,
          5.388633211235645,
          0.37751283639979283,
          2.286102627386449,
          0.4203574207406641,
          91.71652974781624,
          0.2954028745550458,
          0.17023273281517004,
          2.31383702998053,
          0.5379398804493485,
          3.1546004782626174,
          1.766884990790868,
          3.478624828486648,
          0.6943393875008832,
          29.500991056331127,
          3.066708183456385,
          0.5734165977690162,
          24.01491352448711,
          1.095255455294674,
          0.11114456342308487,
          1.9266322081399876,
          3.042126254256605,
          0.06620414098203908,
          35.19591398522819,
          2.2284732554408233,
          1.3295636165646727,
          1.0541831481889923,
          72.87101935476568,
          1.1180405557804876,
          0.3585788337062158,
          348.3894572822255,
          0.25743899036951773,
          1.1264478454386246,
          10.185083729458961,
          3.5386283118110455,
          37.1323992290926,
          18.360507405376858,
          0.2351905351982442,
          0.2759657288455855,
          3.7966736180833247,
          2.8865174386100003,
          0.589461048104602,
          0.6431750075504299,
          0.7361981666365172,
          4.469144922068845,
          6.1150183389762045,
          0.042784176296954815,
          0.10567229063440932,
          5.96157177129148,
          2.6677540369619237,
          1.3402900338565351,
          1.367312407395545,
          13.664989261300748,
          0.9612713702898689,
          0.5686988341548401,
          4.105418919870371,
          0.008187081099122456,
          1.3527355558087795,
          0.8702589210488286,
          0.2747357401026837,
          8.243944998458932,
          2.3882094454489966,
          3.1947764069643307,
          1.1160568650256817,
          0.4393345952243945,
          1.0190443797219502,
          0.5205560320809954,
          0.6718377154908696,
          2.4505444785242347,
          0.13014884052427075,
          2.1522516842945265,
          0.18107508566395503,
          0.651033826515255,
          3.957544249330776,
          6.638047000403844,
          219.15048883026336,
          96.17280399356943,
          0.6386761146179772,
          1.9298791812013192,
          16.690646691808947,
          5.214469475245701,
          0.20325495370052976,
          4.315397905616588,
          1.3284432694846187,
          1.3835675105320882,
          0.034725623358527954,
          0.003361844368758654,
          1.5276363108621092,
          1.586028852941881,
          3.1177059573710517,
          0.7840460314328088,
          0.9438135715249886,
          0.3112263216448223,
          3.367235303852534,
          1.5781328798208587,
          39.37420409235566,
          0.00873663775654127,
          0.6931611682124507,
          23.421742220490703,
          0.08089047227059526,
          2.7603325146555138,
          11.537507414431204,
          0.7860468628039319,
          42.08261497125316,
          0.8300059842897077,
          1.0130992942624708,
          0.009844337930973706,
          0.43538248487360576,
          1.5408008031160871,
          2.2693920203097684,
          0.08170164034621775,
          0.35814463128935514,
          0.6971834890566688,
          1.258028573999723,
          4.0844845352631385,
          56.06781122757599,
          0.7631026996013334,
          0.41576231492724375,
          1.346297779949285,
          2.6283290335998,
          1.8992521879975848,
          2.1237355471119708,
          0.07369526414577338,
          0.10866092837688748,
          65.35646089354604,
          1.495684156924122,
          5.797800324826811,
          1.094000119994368,
          0.16730151421021924,
          0.11528553198380198,
          2.5602701685529476,
          1.591540209060058,
          2.645509236308353,
          2.158382709847301,
          0.9155747568896169,
          3.7010589692346474,
          0.07592220933589544,
          10.896837565353891,
          140.15566537090484,
          1.4494083034814937,
          1.81359429499341,
          49.01857368998653,
          0.27903673747190433,
          1.096163840546967,
          9.707658658609574,
          2.713782741621234,
          2.996308629298457,
          4.129102116783794,
          0.08646091122429415
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          208.09434365760814,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          10.675579272058835,
          7.753896446353136,
          7.753896446353136,
          7.753896446353136,
          7.753896446353136,
          7.753896446353136,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          5.219549435695668,
          1.9372619836762968,
          1.9372619836762968,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.6770310225888577,
          0.03277009101774215,
          0.03277009101774215,
          0.03277009101774215,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.02161324615668983,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.012144058631626434,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.01064000413972929,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.008187081099122456,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654,
          0.003361844368758654
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.plot_optimization_history(study).show()   # 최적화를 진행하는 과정을 시각화해줌. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d26e22",
   "metadata": {},
   "source": [
    "- optuna를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "115a0837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:24:44,209] A new study created in memory with name: no-name-9c9d2fe3-8261-4d6d-aa3d-3a27ec22f35b\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:44,481] Trial 0 finished with value: 0.9530516431924884 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.02056502405976375, 'colsample_bytree': 0.7884040863513978}. Best is trial 0 with value: 0.9530516431924884.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:44,627] Trial 1 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.18753917574018916, 'colsample_bytree': 0.5702006148437093}. Best is trial 1 with value: 0.960093896713615.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:44,802] Trial 2 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06964275018292802, 'colsample_bytree': 0.6549227190729764}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:44,928] Trial 3 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.08722144363605948, 'colsample_bytree': 0.7475792415839413}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:45,045] Trial 4 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.12192083266058543, 'colsample_bytree': 0.8933019167906044}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:45,298] Trial 5 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.10868350795363181, 'colsample_bytree': 0.6936363839754637}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:45,593] Trial 6 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.021226316849091587, 'colsample_bytree': 0.6890727186136243}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:45,832] Trial 7 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.19512505789273754, 'colsample_bytree': 0.8932163393625736}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:46,097] Trial 8 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.07715508824591907, 'colsample_bytree': 0.5558532424014269}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:46,317] Trial 9 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09166536938648104, 'colsample_bytree': 0.820602721343688}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:46,705] Trial 10 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.051050650150334664, 'colsample_bytree': 0.5022887099116516}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:46,845] Trial 11 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.14243144359809046, 'colsample_bytree': 0.6719121829530648}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:46,968] Trial 12 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.14739246812789214, 'colsample_bytree': 0.6365023695849489}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:47,154] Trial 13 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.14884580864016012, 'colsample_bytree': 0.6402366869945284}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:47,407] Trial 14 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05541976038999184, 'colsample_bytree': 0.7282604518802577}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:47,548] Trial 15 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.14172045527421087, 'colsample_bytree': 0.6102506668119274}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:47,712] Trial 16 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.17163996305226303, 'colsample_bytree': 0.9966823493196728}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:47,899] Trial 17 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.057299276920990204, 'colsample_bytree': 0.6634141555862693}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:48,078] Trial 18 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.11756587063886317, 'colsample_bytree': 0.8141259193121857}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:48,377] Trial 19 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.118616208967847, 'colsample_bytree': 0.8371368638447287}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:48,643] Trial 20 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07196473171749002, 'colsample_bytree': 0.9967641651552066}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:48,926] Trial 21 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06892350478572372, 'colsample_bytree': 0.9826016007358396}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:49,211] Trial 22 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.037950497164174604, 'colsample_bytree': 0.9330066962532919}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:49,399] Trial 23 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.09820879694732661, 'colsample_bytree': 0.7870485896774034}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:49,659] Trial 24 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.07595473497962241, 'colsample_bytree': 0.8630287546094841}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:49,976] Trial 25 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.039207548942844436, 'colsample_bytree': 0.95860286992779}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:50,293] Trial 26 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.12667943383983832, 'colsample_bytree': 0.9254184380314987}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:50,612] Trial 27 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.10410294388115363, 'colsample_bytree': 0.7797591212584232}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:50,841] Trial 28 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.0869786315111171, 'colsample_bytree': 0.7382251645938643}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:51,068] Trial 29 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.06676369850438, 'colsample_bytree': 0.8206366401707171}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:51,485] Trial 30 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.03190474690943239, 'colsample_bytree': 0.5917873567470038}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:51,614] Trial 31 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.16253925720027962, 'colsample_bytree': 0.7078181693082244}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:51,756] Trial 32 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.136619167897344, 'colsample_bytree': 0.6586127013309897}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:51,955] Trial 33 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.16361042010076204, 'colsample_bytree': 0.766254711559864}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:52,145] Trial 34 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.180225438645706, 'colsample_bytree': 0.7725261549505711}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:52,316] Trial 35 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.15934749222088704, 'colsample_bytree': 0.758106430489485}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:52,534] Trial 36 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.10880432450387678, 'colsample_bytree': 0.8587997602683287}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:52,791] Trial 37 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.08460841431329014, 'colsample_bytree': 0.8110445448672025}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:52,971] Trial 38 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.12644820815381155, 'colsample_bytree': 0.5551036701914512}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:53,208] Trial 39 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.18869196224697043, 'colsample_bytree': 0.721205653507948}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:53,776] Trial 40 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.020738175973200712, 'colsample_bytree': 0.8858813557557654}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:53,931] Trial 41 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.15961032581711238, 'colsample_bytree': 0.6794467842734933}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:54,071] Trial 42 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.11588079074929698, 'colsample_bytree': 0.7018377359658421}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:54,212] Trial 43 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.11386549930834246, 'colsample_bytree': 0.7550337661829873}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:54,385] Trial 44 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0994644871621034, 'colsample_bytree': 0.6995001577307702}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:54,691] Trial 45 finished with value: 0.9507042253521126 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.011377757008039294, 'colsample_bytree': 0.6433428623865913}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:54,937] Trial 46 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.13172117493891497, 'colsample_bytree': 0.8004568667035012}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:55,130] Trial 47 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.09368522009906607, 'colsample_bytree': 0.6006467179126838}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:55,255] Trial 48 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.19822932703924845, 'colsample_bytree': 0.7128046784074331}. Best is trial 2 with value: 0.9671361502347416.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27956\\3633044676.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:24:55,547] Trial 49 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.07874549508683262, 'colsample_bytree': 0.9183056858209073}. Best is trial 2 with value: 0.9671361502347416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671361502347416\n",
      "{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06964275018292802, 'colsample_bytree': 0.6549227190729764}\n"
     ]
    }
   ],
   "source": [
    "# 1. 목적 함수 \n",
    "def xgb_optuna_objective(trial) : \n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10, 1),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.2), \n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1)\n",
    "    }\n",
    "    xgb_clf = XGBClassifier(**params)\n",
    "    return cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "\n",
    "# 2. study 객체 생성 -> 최적화\n",
    "study = optuna.create_study(direction='maximize')  # direction을 최소화 시키는 방향으로 최적화를 진행함\n",
    "study.optimize(xgb_optuna_objective, n_trials=50)\n",
    "\n",
    "# 3. 결과 출력\n",
    "print(study.best_value)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa7de0",
   "metadata": {},
   "source": [
    "## HyperOpt vs Optuna\n",
    "\n",
    "- HyperOpt\n",
    "    - 'colsample_bytree': np.float64(0.6403349404192222),\n",
    "    - 'learning_rate': np.float64(0.1351017557199938),\n",
    "    - 'max_depth': np.float64(4.0),\n",
    "    - 'n_estimators': np.float64(400.0)\n",
    "\n",
    "- Optuna\n",
    "    - 'colsample_bytree': 0.6549227190729764, \n",
    "    - 'learning_rate': 0.06964275018292802,\n",
    "    - 'max_depth': 5,\n",
    "    - 'n_estimators': 200,   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7089c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt 최적 파라미터 적용\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        53\n",
      "           1       0.99      0.99      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "Optuna 최적 파라미터 적용\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        53\n",
      "           1       0.99      0.99      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning:\n",
      "\n",
      "[10:33:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"leaning_rate\" } are not used.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_hopt = XGBClassifier(\n",
    "    n_estimators = 500, \n",
    "    max_depth = 6, \n",
    "    leaning_rate = 0.17, \n",
    "    colsample_bytree = 0.5\n",
    ")\n",
    "\n",
    "xgb_optuna = XGBClassifier(\n",
    "    n_estimators = 500, \n",
    "    max_depth = 7, \n",
    "    leaning_rate = 0.14, \n",
    "    colsample_bytree = 0.53\n",
    ")\n",
    "\n",
    "xgb_hopt.fit(X_train, y_train)\n",
    "xgb_optuna.fit(X_train, y_train)\n",
    "\n",
    "hopt_pred = xgb_hopt.predict(X_test)\n",
    "optuna_pred = xgb_optuna.predict(X_test)\n",
    "\n",
    "print('HyperOpt 최적 파라미터 적용')\n",
    "print(classification_report(y_test, hopt_pred))\n",
    "print('Optuna 최적 파라미터 적용')\n",
    "print(classification_report(y_test, optuna_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd824e",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 찾는 방법\n",
    "1. 일일 대조 \n",
    "2. cv 교차 검증 방식으로 최적의 파라미터 찾기 \n",
    "3. hyperopt\n",
    "4. optuna - randomsearchcv와 유사하다고 볼수 있음. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
