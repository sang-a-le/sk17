{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88efc5c5",
   "metadata": {},
   "source": [
    "# 출력층 설계 (Output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30304320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 18.9/216.1 MB 91.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 28.3/216.1 MB 94.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 37.2/216.1 MB 60.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 60.3/216.1 MB 72.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 64.0/216.1 MB 60.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 81.8/216.1 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 104.3/216.1 MB 70.8 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 122.9/216.1 MB 72.7 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 142.9/216.1 MB 75.4 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 152.0/216.1 MB 72.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 172.2/216.1 MB 74.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 185.6/216.1 MB 76.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 194.8/216.1 MB 71.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 207.9/216.1 MB 70.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 70.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 216.1/216.1 MB 64.5 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB ? eta 0:00:00\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 69.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 77.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 110.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchaudio]\n",
      "   ----------------------------------- ---- 7/8 [torchaudio]\n",
      "   ---------------------------------------- 8/8 [torchaudio]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f33ade",
   "metadata": {},
   "source": [
    "### 소프트 맥스 오버플로우 방지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_2828\\2980363771.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  exp_z = np.exp(z)\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_2828\\2980363771.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  return exp_z / np.sum(exp_z)   # x = np.array([1000, 1001, 1002]) : [nan nan nan] = 표현가능한 숫자의 범위를 벗어남. overflow / e^x 값이 분모로 들어가기 때문에 계산 불가능임.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z) :           # 기본모델 : z에 큰값을 넣었을 때 nan 반환\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z)   # x = np.array([1000, 1001, 1002]) : [nan nan nan] = 표현가능한 숫자의 범위를 벗어남. overflow / e^x 값이 분모로 들어가기 때문에 계산 불가능임. \n",
    "\n",
    "\n",
    "def stable_softmax(z) :    # 오버플로우 방지 \n",
    "    exp_z = np.exp(z - np.max(z))   # x = np.array([1000, 1001, 1002]) 를 -2, -1, 0으로 반환해서 계산 \n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "x = np.array([1000, 1001, 1002])  \n",
    "print(softmax(x))   \n",
    "print(stable_softmax(x))   \n",
    "\n",
    "# 소프트맥스 함수는 비율로 계산하기 때문에 똑같은 값을 다 빼주면 동일한 비율 반환. 따라서 max 값을 빼줘도 동일한 비율 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4dbd52",
   "metadata": {},
   "source": [
    "- pytorch 라이브러리 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a019bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor([1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_27976\\1370867057.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_output = F.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F   # .nn. : 뉴런네트워크 , \n",
    "\n",
    "x = torch.tensor([1000, 1001, 1002], dtype=torch.float32)   # softmax는 torch의 tensor 타입에 대해서만 연산함. 또한 dtype=torch.float32 데이터 타입도 float 로 맞춰줘야 계산가능\n",
    "\n",
    "softmax_output = F.softmax(x)\n",
    "print(softmax_output)\n",
    "\n",
    "sigmoid_output = torch.sigmoid(x)     # 시그모이드는 torch 라이브러리에 있음. \n",
    "print(sigmoid_output)                 # 0~1사이의 값을 넣어야함. but x 값이 너무 커서 1로 극단적인 값을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03401369",
   "metadata": {},
   "source": [
    "### 손실 함수와 연계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5894734859466553\n",
      "1.5474185943603516\n",
      "1.5059770345687866\n",
      "1.4651741981506348\n",
      "1.4250311851501465\n",
      "1.3855628967285156\n",
      "1.3467824459075928\n",
      "1.3087072372436523\n",
      "1.2713618278503418\n",
      "1.2347733974456787\n"
     ]
    }
   ],
   "source": [
    "# 다중클래스 모델을 간단하게 만들어서 학습시켜보자 (흐름만 이해하기). 출력층들이 손실함수와 얼마나 연관이 있는지 알아보자~~\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "# 간단한 다중 클래스 분류 모델 정의 \n",
    "class SimpleMultiClassModel(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(SimpleMultiClassModel, self).__init__()\n",
    "        self.fc = nn.Linear(5, 3) \n",
    "\n",
    "    def forward(self, x) :      # forward 는 순방향으로 진행하는 것 : 예측하는 것 / 오차역전파법에서 사용되는 개념(함수명을 설명하기 위해 나온 이야기~)\n",
    "        return self.fc(x)  \n",
    "    \n",
    "model = SimpleMultiClassModel()\n",
    "criterion = nn.CrossEntropyLoss()                         # 손실함수 (다음주 예정사항)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)       # optim = 가중치 최적화 함수 모듈 - model.parameters() 모델파라미터 부여 / 중에서 adam 사용 (다음주 예정사항) / lr=러닝레이트(학습률)\n",
    "\n",
    "inputs = torch.randn(4, 5)            # 입력값 : 4,5형태의 텐서(배열) 반환 \n",
    "labels = torch.tensor([0, 2, 1, 0])   # 정답에 대한 라벨 데이터\n",
    "\n",
    "for _ in range(10):\n",
    "    preds = model(inputs)                # 순전파\n",
    "    loss = criterion(preds, labels)      # 손실 계산\n",
    "    print(loss.item())         \n",
    "\n",
    "    optimizer.zero_grad()                # 기울기 초기화 (이전 단계에서 계산된 기울기를 0으로 초기화)\n",
    "    loss.backward()                      # 역전파 (손실에 대한 역전파 수행 - 파라미터에 대한 기울기 계산)\n",
    "    optimizer.step()                     # 가중치 업데이트 (계산된 기울기를 사용하여 옵티마이저가 모델 파라미터 갱신)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
